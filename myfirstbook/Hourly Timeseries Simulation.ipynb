{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly Timeseries Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transmission planners increasingly require accurate hourly simulations to assess the operational impact of integrating new renewable generation or network reinforcements. While the static load flow cases are useful, there is a need within the industry for more depth in order to understand how new generators or network reinforcements impact the system during normal operation. Unlike traditional tools (e.g., PLEXOS, GAMS, PSSE, TARA), this Python-based solution using PandaPower significantly reduces cost and analysis time while maintaining accuracy.\n",
    "\n",
    "In light of the recent decision on Large Energy User connection, there will be a push for Eirgrid to create a network capacity tool similar to what has been created for the distribution network by ESB. It may not be feasible to have a new transmission network capacity tool supported by data from quarterly simulations using PLEXOS. Instead, this pandapower based tool is a capable alternative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first stage in the timeseries simulation part of this tool consists of creating a balanced power system model for each hour. The model is given a set of hourly values representing demand factor of peak, wind capacity factor and solar capacity factor. Each hourly simulation is conducted by creating a balanced load-generation model, dispatching generation units according to EirGridâ€™s priority dispatch rules, and ensuring network constraints are observed. \n",
    "\n",
    "This leaves room for edits as needed by the user, but keeps the focus on hourly load flow and realistic system dispatch. If the user would like specific battery storage projects with duration of 8 hours and others with 4 hour duration, they are able to make changes to reflect any unique disptach sensitivity. Currently the script operates dispatching all battery storage uniformly, charging when renewable generation is high and discharging when renewables are low. This is another area that can be modified, if specific projects seek to dispatch based on local generation/demand rather than central system-wide dispatch.\n",
    "\n",
    "A balanced and converged network model is created for each hour at a rate of roughly 1463 hours (~2 months) in under 25 minutes using standard AC newton raphson powerflow solutions.\n",
    "\n",
    "After the dispatch balancing is completed for each network model, the nodal analysis begins. Contingency analysis is completed for each hour, identifying the worst case contingency for each branch in the system greater or equal to 110kV. For each branch that experiences a worst case contingency greater than a user-defined \"overload threshold\", shift factors are gathered and aggregated according to each bus. In doing this, the user can determine which nodes have a greater contribution to all worst case overloads for each hour in the simulation. There are two functional ways to complete this, either by AC powerflow for both the intact system and AC contingency analysis, or AC power flow on the intact system with DC LODF approximation for the contingency analysis. The latter being the most time efficient, capable of processing 2 months of hourly data in 42 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ECP GSS](South_IRL.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/codespace/.python/current/bin/python3\n",
      "pandapower version: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandapower as pp\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"pandapower version:\", pp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable: /home/codespace/.python/current/bin/python3\n",
      "sys.path:\n",
      "   /home/codespace/.python/current/lib/python312.zip\n",
      "   /home/codespace/.python/current/lib/python3.12\n",
      "   /home/codespace/.python/current/lib/python3.12/lib-dynload\n",
      "   \n",
      "   /home/codespace/.local/lib/python3.12/site-packages\n",
      "   /home/codespace/.python/current/lib/python3.12/site-packages\n",
      "pandapower version: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Executable:\", sys.executable)\n",
    "print(\"sys.path:\")\n",
    "for p in sys.path:\n",
    "    print(\"  \", p)\n",
    "\n",
    "import pandapower as pp\n",
    "print(\"pandapower version:\", pp.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded adjusted_network_1162.p\n",
      "Load flow complete.\n",
      "Loaded bus-level aggregator data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"820\"\n",
       "    src=\"iframe_figures/figure_6.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe_connected\"\n",
    "\n",
    "\n",
    "# Optional: Uncomment to disable numba warnings (or install numba in your poetry environment)\n",
    "# pp.options.numba = False\n",
    "\n",
    "PF_SETTINGS = {\n",
    "    \"algorithm\": \"nr\",\n",
    "    \"max_iteration\": 100,\n",
    "    \"tolerance_mva\": 5e-3,\n",
    "    \"init\": \"dc\",\n",
    "    \"enforce_q_lims\": True,\n",
    "    \"calculate_voltage_angles\": True,\n",
    "    \"logging\": False,\n",
    "    \"voltage_depend_loads\": False,\n",
    "    \"v_debug\": True\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Load or Create the pandapower Network\n",
    "# =============================================================================\n",
    "try:\n",
    "    net = pp.from_pickle(\"adjusted_network_1162.p\")\n",
    "    print(\"Loaded adjusted_network_1162.p\")\n",
    "except Exception as e:\n",
    "    print(\"Could not load 'adjusted_network_1162.p'. Creating a demo network. Error:\", e)\n",
    "    net = pp.create_empty_network()\n",
    "    b1 = pp.create_bus(net, vn_kv=110, name=\"Bus A\")\n",
    "    b2 = pp.create_bus(net, vn_kv=110, name=\"Bus B\")\n",
    "    b3 = pp.create_bus(net, vn_kv=110, name=\"Bus C\")\n",
    "    pp.create_line(net, from_bus=b1, to_bus=b2, length_km=10, std_type=\"149-AL1/24-ST1A 110.0\")\n",
    "    pp.create_line(net, from_bus=b2, to_bus=b3, length_km=15, std_type=\"149-AL1/24-ST1A 110.0\")\n",
    "\n",
    "net.bus[\"in_service\"] = True\n",
    "net.line[\"in_service\"] = True\n",
    "\n",
    "pp.runpp(net, **PF_SETTINGS)\n",
    "print(\"Load flow complete.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Bus Filtering (Using Original Script Logic)\n",
    "# =============================================================================\n",
    "if \"geodata\" in net.bus.columns:\n",
    "    filtered_buses = net.bus[\n",
    "        (net.bus[\"vn_kv\"] >= 110) &\n",
    "        (net.bus[\"in_service\"] == True) &\n",
    "        (net.bus[\"x1\"] > 0) &\n",
    "        (net.bus[\"y1\"] > 0)\n",
    "    ].copy()\n",
    "    filtered_buses[\"x1\"] = filtered_buses[\"x1\"]\n",
    "    filtered_buses[\"y1\"] = filtered_buses[\"y1\"]\n",
    "else:\n",
    "    filtered_buses = net.bus[(net.bus[\"vn_kv\"] >= 110) & (net.bus[\"in_service\"] == True)].copy()\n",
    "    np.random.seed(42)\n",
    "    filtered_buses[\"x1\"] = np.random.uniform(0, 100, size=len(filtered_buses))\n",
    "    filtered_buses[\"y1\"] = np.random.uniform(0, 100, size=len(filtered_buses))\n",
    "\n",
    "# Create a DataFrame similar to the original \"relevant_bus\"\n",
    "relevant_bus = pd.DataFrame({\n",
    "    \"index\": filtered_buses.index,\n",
    "    \"x1\": filtered_buses[\"x1\"],\n",
    "    \"y1\": filtered_buses[\"y1\"],\n",
    "    \"bus_names\": filtered_buses[\"bus_names\"]\n",
    "})\n",
    "bus_ids = relevant_bus[\"index\"].tolist()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Line Filtering (Using Original Script Logic)\n",
    "# =============================================================================\n",
    "filtered_lines = net.line[net.line[\"in_service\"] == True].copy()\n",
    "filtered_lines = filtered_lines[\n",
    "    filtered_lines[\"from_bus\"].isin(bus_ids) & \n",
    "    filtered_lines[\"to_bus\"].isin(bus_ids)\n",
    "]\n",
    "\n",
    "results = filtered_lines.copy()\n",
    "results[\"loading_percent\"] = net.res_line[\"loading_percent\"]\n",
    "results[\"p_from_mw\"] = net.res_line[\"p_from_mw\"]\n",
    "results[\"name\"] = results[\"name\"].fillna(\"Unnamed Line\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Load Global Contingency Aggregator Data and Build Lookup\n",
    "# =============================================================================\n",
    "global_contingency_df = pd.read_csv(\"global_contingency_aggregator_June_Sept.csv\")\n",
    "def normalize_name(name):\n",
    "    return \" \".join(str(name).split()).strip().lower()\n",
    "\n",
    "cont_map = {}\n",
    "for i, row_c in global_contingency_df.iterrows():\n",
    "    bname = normalize_name(row_c[\"Branch_Name\"])\n",
    "    max_post_flow = row_c[\"Max_Post_Contingency_Flow_Percent\"]\n",
    "    worst_outage = row_c[\"Worst_Case_Outage_For_Max\"]\n",
    "    cont_map[bname] = (max_post_flow, worst_outage)\n",
    "default_cont_data = (\"N/A\", \"No data\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Load Bus Aggregator Data from bus_lodf_aggregator_June_Sept.csv\n",
    "# =============================================================================\n",
    "try:\n",
    "    bus_lodf_df = pd.read_csv(\"bus_lodf_aggregator_June_Sept.csv\")\n",
    "    def normalize_bus_name(name):\n",
    "        return \" \".join(str(name).split()).lower()\n",
    "    bus_lodf_df[\"Normalized_Bus_Name\"] = bus_lodf_df[\"Bus_Name\"].apply(normalize_bus_name)\n",
    "    \n",
    "    best_list = []\n",
    "    for idx, row in relevant_bus.iterrows():\n",
    "        bus_name = row[\"bus_names\"]\n",
    "        norm_bus_name = normalize_bus_name(bus_name)\n",
    "        match = bus_lodf_df[bus_lodf_df[\"Normalized_Bus_Name\"] == norm_bus_name]\n",
    "        if not match.empty:\n",
    "            cumulative_otdf = match.iloc[0][\"Cumulative_OTDF\"]\n",
    "            maximum_otdf = match.iloc[0][\"Maximum_OTDF\"]\n",
    "        else:\n",
    "            cumulative_otdf = np.nan\n",
    "            maximum_otdf = np.nan\n",
    "        best_list.append({\n",
    "            \"Bus_ID\": row[\"index\"],\n",
    "            \"PTDF_Sum\": cumulative_otdf,\n",
    "            \"LODF_Percentile\": maximum_otdf\n",
    "        })\n",
    "    best_results_full_discharge = pd.DataFrame(best_list)\n",
    "    print(\"Loaded bus-level aggregator data.\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading bus_lodf_aggregator_June_Sept.csv, using dummy data:\", e)\n",
    "    best_results_full_discharge = pd.DataFrame({\n",
    "        \"Bus_ID\": relevant_bus[\"index\"],\n",
    "        \"PTDF_Sum\": np.random.uniform(0, 100, size=len(relevant_bus)),\n",
    "        \"LODF_Percentile\": np.random.uniform(0, 100, size=len(relevant_bus))\n",
    "    })\n",
    "\n",
    "contingency_trigger = True\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Plotting Function (plot_network)\n",
    "# =============================================================================\n",
    "def plot_network(relevant_bus, results, bus_ids, best_results_full_discharge, cont_map, contingency_trigger=True):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Build nodal aggregated dictionary.\n",
    "    best_results_discharge_dict = {}\n",
    "    for i, row in best_results_full_discharge.iterrows():\n",
    "        bus_id = row[\"Bus_ID\"]\n",
    "        best_results_discharge_dict[bus_id] = (row[\"PTDF_Sum\"], row[\"LODF_Percentile\"])\n",
    "    \n",
    "    # Updated helper functions with NaN checks.\n",
    "    def get_line_color(val, min_val=0, max_val=100):\n",
    "        if pd.isna(val):\n",
    "            return \"rgba(128,128,128,1)\"\n",
    "        frac = np.interp(val, [min_val, max_val], [0, 1])\n",
    "        red = int(255 * frac)\n",
    "        blue = int(255 * (1 - frac))\n",
    "        return f\"rgba({red}, 0, {blue}, 1)\"\n",
    "    \n",
    "    def get_node_color(val, min_val=0, max_val=100):\n",
    "        if pd.isna(val):\n",
    "            return \"rgba(128,128,128,1)\"\n",
    "        frac = np.interp(val, [min_val, max_val], [0, 1])\n",
    "        red = int(255 * frac)\n",
    "        blue = int(255 * (1 - frac))\n",
    "        return f\"rgba({red}, 0, {blue}, 1)\"\n",
    "    \n",
    "    # Build adjusted coordinates: key = bus ID, value = (x, y, bus name)\n",
    "    adjusted_coords = {\n",
    "        row[\"index\"]: (float(row[\"x1\"]), float(row[\"y1\"]), row[\"bus_names\"])\n",
    "        for i, row in relevant_bus.iterrows() if pd.notna(row[\"x1\"]) and pd.notna(row[\"y1\"])\n",
    "    }\n",
    "    \n",
    "    annotations = []\n",
    "    traces = []\n",
    "    \n",
    "    # Plot buses.\n",
    "    for bus_id, (x, y, bname) in adjusted_coords.items():\n",
    "        ptdf_sum, lodf_pct = best_results_discharge_dict.get(bus_id, (\"N/A\", \"N/A\"))\n",
    "        default_color = \"rgba(128,128,128,1)\"\n",
    "        node_color = default_color\n",
    "        if isinstance(lodf_pct, (int, float)):\n",
    "            node_color = get_node_color(lodf_pct)\n",
    "        text_node = f\"PTDF Sum: {ptdf_sum}, LODF: {lodf_pct}\"\n",
    "        traces.append(go.Scatter(\n",
    "            x=[x], y=[y],\n",
    "            mode=\"markers\",\n",
    "            text=[text_node],\n",
    "            hoverinfo=\"text\",\n",
    "            marker=dict(size=10, color=default_color),\n",
    "            name=f\"Bus {bus_id}\"\n",
    "        ))\n",
    "        annotations.append(dict(\n",
    "            x=x, y=y, text=bname, showarrow=False,\n",
    "            font=dict(size=10, color=\"#ffffff\"), bgcolor=node_color, opacity=0.8\n",
    "        ))\n",
    "    \n",
    "    # Plot lines.\n",
    "    for _, r_row in results.iterrows():\n",
    "        loading_percent = r_row[\"loading_percent\"]\n",
    "        if pd.isna(loading_percent) or loading_percent == 0:\n",
    "            continue\n",
    "        if (r_row[\"from_bus\"] not in adjusted_coords) or (r_row[\"to_bus\"] not in adjusted_coords):\n",
    "            continue\n",
    "        from_coords = adjusted_coords[r_row[\"from_bus\"]]\n",
    "        to_coords = adjusted_coords[r_row[\"to_bus\"]]\n",
    "        \n",
    "        line_name = str(r_row[\"name\"])\n",
    "        norm_line_name = normalize_name(line_name)\n",
    "        cont_loading, cause_name = cont_map.get(norm_line_name, default_cont_data) if contingency_trigger else (\"N/A\", \"No data\")\n",
    "        line_color = get_line_color(loading_percent)\n",
    "        \n",
    "        traces.append(go.Scatter(\n",
    "            x=[from_coords[0], to_coords[0]],\n",
    "            y=[from_coords[1], to_coords[1]],\n",
    "            mode=\"lines\", line=dict(color=line_color, width=3),\n",
    "            hoverinfo=\"none\"\n",
    "        ))\n",
    "        mid_x = (from_coords[0] + to_coords[0]) / 2\n",
    "        mid_y = (from_coords[1] + to_coords[1]) / 2\n",
    "        \n",
    "        text_line = (f\"Line: {line_name}<br>\"\n",
    "                     f\"Intact loading: {loading_percent:.1f}%<br>\"\n",
    "                     f\"Post-Contingency: {cont_loading}%<br>\"\n",
    "                     f\"Cause: {cause_name}\")\n",
    "        traces.append(go.Scatter(\n",
    "            x=[mid_x], y=[mid_y],\n",
    "            mode=\"markers\", marker=dict(size=5, color=line_color),\n",
    "            text=[text_line], hoverinfo=\"text\"\n",
    "        ))\n",
    "        \n",
    "        if r_row[\"p_from_mw\"] >= 0:\n",
    "            arrow_coords = (to_coords[0], to_coords[1], from_coords[0], from_coords[1])\n",
    "        else:\n",
    "            arrow_coords = (from_coords[0], from_coords[1], to_coords[0], to_coords[1])\n",
    "        annotations.append(dict(\n",
    "            x=mid_x, y=mid_y,\n",
    "            ax=arrow_coords[2], ay=arrow_coords[3],\n",
    "            xref=\"x\", yref=\"y\", axref=\"x\", ayref=\"y\",\n",
    "            showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=2, arrowcolor=line_color\n",
    "        ))\n",
    "    \n",
    "    fig.add_traces(traces)\n",
    "    fig.update_layout(\n",
    "        annotations=annotations,\n",
    "        title=\"Network Diagram with Post-Contingency Results\",\n",
    "        showlegend=False,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        yaxis=dict(autorange=\"reversed\")\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Call the Plot Function\n",
    "# =============================================================================\n",
    "plot_network(\n",
    "    relevant_bus=relevant_bus,\n",
    "    results=results,\n",
    "    bus_ids=bus_ids,\n",
    "    best_results_full_discharge=best_results_full_discharge,\n",
    "    cont_map=cont_map,\n",
    "    contingency_trigger=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ECP GSS](South_IRL_Circuit.png)\n",
    "![ECP GSS](South_IRL_Node.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results include projects that are energized, contracted, or processing up to ECP-2.5. The study year selected is 2031 with demand scaled appropriately based on latest data in line with the most recent TYTFS. The \"Outage Transfer Distribution Factor\" is scaled based on the severity of the overload caused by the worst case contingency and aggregated accross each hour of the simulation. If an outage results in a branch loading less than 100%, the OTDF values for each node are not gathered. Similarly, if an outage results in a branch loading higher than 100%, but another outage results in a higher loading on that same branch, then the OTDF values are only gathered for the relevant \"worst case contingency\". The user has the ability to edit the overload threshold as well as implement a threshold for OTDF values i.e. the user may want to omit OTDF values less than 0.1 if they are only concerned with the nodes that have a significant contribution to the branch of focus. For the above sample results, there was no threshold used for OTDF values. \n",
    "\n",
    "There are many conclusions that can be drawn from the data. If using the data to compare different station locations for a new large energy user or battery storage, one might focus on nodes with high levels of cumulative OTDF values while making sure to reference the associated branch values for alternative worst case contingencies. The above 110kV nodes in the southern region of the network present opportunities for added demand projects to strategically alleviate transmission contingency overloads driven by renewable energy generation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
