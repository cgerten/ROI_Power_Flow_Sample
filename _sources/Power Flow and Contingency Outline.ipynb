{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b816b4d9",
   "metadata": {},
   "source": [
    "# Power Flow and Contingency Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704a820",
   "metadata": {},
   "source": [
    "The tool is built and regularly updated using public sources including but not limited to Eirgrid's Ten Year Transmission Forecast Statement (TYTFS). The model operates in a simple manner for powerflow analysis, utilizing the open source tool PandaPower and other python functionality for data processing. It can easily be updated to reflect a range of scenarios and study years in order to meet the needs of the user. Note: The current model focuses exclusively on the Republic of Ireland's (ROI) transmission network, excluding Northern Ireland (NI). Expansion is possible upon request.\n",
    "\n",
    "Outputs can come in many forms, line loading and bus results can be produced by csv files in \"Results\" folder. Various plots are also provided for a visual representation of the load flow, worst case contingency and test energy storage net impact. Load flow is solved using ACPF newton raphson using DC initialization. Some of the practical applications are senstivity testing with and without network reinforcements, connection method comparisons, and general loadflow injection screening studies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d64c48",
   "metadata": {},
   "source": [
    "**Determining optimal system wind and solar capacity factors to obtain convergence**\n",
    "\n",
    "- In order to build cases for screening, it's important to first determine what the maximum tollerable wind and solar capacity factors are that will still allow each case to solve and converge properly. The goal being to find the levels of renewable energy dispatch that allow the system to converge for each unique case. Each unique case is meant to represent a slice of time from summer or winter peak demand and meeting it with the maximum amount of wind or solar generation up to the capacity factors input by the user. This is informed by assessing hourly dispatch data from ECP constraint reports, Tomorrow's Energy Scenarios (TES), and other data from Eirgrid and ESB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a239b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.3\n",
      "total conv generation at script begin: 5953.547500000001, percentage of total: 17.76058566483939\n",
      "total offshore generation at script begin: 3641.2, percentage of total: 10.86240506568784\n",
      "total onshore generation at script begin: 7803.774001, percentage of total: 23.280169790164084\n",
      "total solar generation at script begin: 8932.4, percentage of total: 26.647079811257296\n",
      "total storage generation at script begin: 4689.6, percentage of total: 13.989985388347165\n",
      "total interconnector generation at script begin: 1700.0, percentage of total: 5.071429367150755\n",
      "total pw load: 5849.0199999999995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandapower as pp\n",
    "import logging\n",
    "import pandapower.networks as networks\n",
    "import pandapower.contingency\n",
    "import pandapower.control\n",
    "import pandapower.timeseries\n",
    "import pandapower.plotting\n",
    "import lightsim2grid\n",
    "print(lightsim2grid.__version__)\n",
    "import plotly.graph_objects as go\n",
    "from pandapower.pypower.makePTDF import makePTDF\n",
    "from pandapower.pypower.makeLODF import makeLODF, makeOTDF\n",
    "from pandapower.pd2ppc import _pd2ppc\n",
    "from pandapower.pf.makeYbus_numba import makeYbus\n",
    "from pandapower.pypower.idx_brch import F_BUS, T_BUS, BR_R, BR_X, BR_B, BR_STATUS, SHIFT, TAP, BR_R_ASYM, BR_X_ASYM\n",
    "from pandapower.toolbox.data_modification import create_continuous_bus_index\n",
    "import copy\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load network data from Model folder\n",
    "#bus_names_df = pd.read_csv(\"Model/bus_data.csv\")\n",
    "bus_df = pd.read_csv(\"Model/bus_data.csv\")\n",
    "line_df = pd.read_csv('Model/line_data.csv')\n",
    "generator_df = pd.read_csv('Model/generator_data.csv')\n",
    "transformer_df = pd.read_csv('Model/transformers_data.csv')\n",
    "reactive_df = pd.read_csv('Model/reactive_data.csv')\n",
    "load_df_SP = pd.read_csv('Model/load_data_SP2031.csv')\n",
    "load_df_WP = pd.read_csv('Model/load_data_WP2031.csv')\n",
    "load_df_SV = pd.read_csv('Model/load_data_SV2031.csv')\n",
    "\n",
    "\n",
    "# Load network\n",
    "net = pp.from_pickle(\"adjusted_network.p\")\n",
    "\n",
    "#Clear network, below is optional if the network needs to be reset\n",
    "#net.bus.drop(net.bus.index, inplace=True)\n",
    "#net.line.drop(net.line.index, inplace=True)\n",
    "#net.load.drop(net.load.index, inplace=True)\n",
    "#net.gen.drop(net.gen.index, inplace=True)\n",
    "#net.trafo.drop(net.trafo.index, inplace=True)\n",
    "\n",
    "# Update functions for transformers, buses, lines, generators, and reactive equipment\n",
    "def update_load_from_csv(net, load_df):\n",
    "    for index, row in load_df.iterrows():\n",
    "        matched_loads = net.load[(net.load.name == row['name'])]\n",
    "        if not matched_loads.empty:\n",
    "            load_index = matched_loads.index[0]\n",
    "            for col in row.index:\n",
    "                net.load.at[load_index, col] = row[col]\n",
    "        else:\n",
    "            print(f\"Warning: load named {row['name']} not found in the network.\")\n",
    "            pp.create_load(net, name=row['name'], bus=row['bus'], p_mw=row['p_mw'], q_mvar=row['q_mvar'], \n",
    "                            in_service=row['in_service'],scaling=row['scaling'])\n",
    "\n",
    "def update_trafo_from_csv(net, transformer_df):\n",
    "    for index, row in transformer_df.iterrows():\n",
    "        trafo_indices = net.trafo[net.trafo.index == row['index']].index\n",
    "        if not trafo_indices.empty:\n",
    "            trafo_index = trafo_indices[0]\n",
    "            for col in row.index:\n",
    "                net.trafo.at[trafo_index, col] = row[col]\n",
    "        else:\n",
    "            print(f\"Warning: Transformer with index {row['index']} not found in the network.\")\n",
    "            pp.create_transformer_from_parameters(net, hv_bus=row['hv_bus'], lv_bus=row['lv_bus'], std_type=\"your_standard_type\",\n",
    "                                                  name=row['name'], sn_mva=row['sn_mva'], vn_hv_kv=row['vn_hv_kv'], vn_lv_kv=row['vn_lv_kv'],\n",
    "                                                  vk_percent=row['vk_percent'], vkr_percent=row['vkr_percent'], pfe_kw=row['pfe_kw'],\n",
    "                                                  i0_percent=row['i0_percent'], shift_degree=row['shift_degree'], tap_side=row['tap_side'],\n",
    "                                                  tap_neutral=row['tap_neutral'], tap_min=row['tap_min'], tap_max=row['tap_max'],\n",
    "                                                  tap_step_percent=row['tap_step_percent'], tap_step_degree=row['tap_step_degree'],\n",
    "                                                  tap_pos=row['tap_pos'], parallel=row['parallel'], in_service=row['in_service'], \n",
    "                                                  max_loading_percent=row['max_loading_percent'],index=row['index'])\n",
    "\n",
    "def update_bus_from_csv(net, bus_df):\n",
    "    for index, row in bus_df.iterrows():\n",
    "        bus_indices = net.bus[net.bus.index == row['index']].index\n",
    "        if not bus_indices.empty:\n",
    "            bus_index = bus_indices[0]\n",
    "            for col in row.index:\n",
    "                net.bus.at[bus_index, col] = row[col]\n",
    "        else:\n",
    "            pp.create_bus(net, vn_kv=row['vn_kv'], name=row['name'], max_vm_pu=row['max_vm_pu'], min_vm_pu=row['min_vm_pu'],\n",
    "                          zone=row['zone'], in_service=row['in_service'], geodata=(row['x1'], row['y1']), index=row['index'])\n",
    "\n",
    "def update_lines_from_csv(net, line_df, max_i_column='max_i_ka'):\n",
    "    for index, row in line_df.iterrows():\n",
    "        line_indices = net.line[net.line.index == row['line_id']].index\n",
    "        if not line_indices.empty:\n",
    "            line_index = line_indices[0]\n",
    "            for col in row.index:\n",
    "                net.line.at[line_index, col] = row[col]\n",
    "        else:\n",
    "            print(f\"Warning: Line with line_id {row['line_id']} not found in the network.\")\n",
    "            pp.create_line_from_parameters(net, from_bus=row['from_bus'], to_bus=row['to_bus'], index=row['line_id'],\n",
    "                                           length_km=row['length_km'], r_ohm_per_km=row['r_ohm_per_km'], \n",
    "                                           x_ohm_per_km=row['x_ohm_per_km'], c_nf_per_km=row['c_nf_per_km'], \n",
    "                                           max_i_ka=row[max_i_column], wp_max_i_ka=row['wp_max_i_ka'],name=row['name'], in_service=row['in_service'], \n",
    "                                           max_loading_percent=row['max_loading_percent'],kV = row['kv_from'])\n",
    "\n",
    "def update_generators_from_csv(net,gen_df):\n",
    "    # Ensure custom columns exist in net.gen. Add them if needed.\n",
    "    for custom_col in ['type_', 'zone']:\n",
    "        if custom_col not in net.gen.columns:\n",
    "            net.gen[custom_col] = 0  # or set a default value if desired\n",
    "        \n",
    "    for index, row in gen_df.iterrows():\n",
    "        matched_generators = net.gen[(net.gen.name == row['name'])]\n",
    "        if not matched_generators.empty:\n",
    "            gen_index = matched_generators.index[0]\n",
    "            for col in row.index:\n",
    "                net.gen.at[gen_index, col] = row[col]        \n",
    "        else:\n",
    "            print(f\"Warning: Generator named {row['name']} not found in the network.\")\n",
    "            pp.create_gen(net, name=row['name'], bus=row['bus'], p_mw=row['p_mw'], vm_pu=row['vm_pu'], \n",
    "                          slack=False, max_q_mvar=row['max_q_mvar'], min_q_mvar=row['min_q_mvar'], \n",
    "                          min_p_mw=row['min_p_mw'], max_p_mw=row['max_p_mw'], in_service=row['in_service'],\n",
    "                          controllable=row['controllable'], max_vm_pu=row['max_vm_pu'], min_vm_pu=row['min_vm_pu'], type_=row['type'],\n",
    "                          zone=row['zone'],scaling=1.0)\n",
    "\n",
    "def update_reactive_from_csv(net, reactive_df):\n",
    "    for index, row in reactive_df.iterrows():\n",
    "        matched_react = net.shunt[(net.shunt.name == row['name'])]\n",
    "        if not matched_react.empty:\n",
    "            react_index = matched_react.index[0]\n",
    "            for col in row.index:\n",
    "                net.shunt.at[react_index, col] = row[col]\n",
    "        else:\n",
    "            print(f\"Warning: Reactive equipment named {row['name']} not found in the network.\")\n",
    "            pp.create_shunt(net, name=row['name'], bus=row['bus'], p_mw=row['p_mw'], q_mvar=row['q_mvar'], \n",
    "                            in_service=row['in_service'])\n",
    "            \n",
    "#Lines below update model if changes have been made such as new generators, lines, busses, loads, etc. . . \n",
    "update_bus_from_csv(net, bus_df)\n",
    "update_generators_from_csv(net, generator_df)\n",
    "update_lines_from_csv(net, line_df)\n",
    "update_trafo_from_csv(net, transformer_df)\n",
    "update_reactive_from_csv(net, reactive_df)\n",
    "update_load_from_csv(net, load_df_SP)\n",
    "\n",
    "wind_types = [17,18,19,20,21,22]\n",
    "all_wind_types = [16,17,18,19,20,21,22]\n",
    "offshore_types = [16]\n",
    "gas_types = [9]\n",
    "solar_types = [23]\n",
    "storage_types = [14]\n",
    "interconnector_type = [49]\n",
    "all_re_types = [16,17,18,19,20,21,22,23]\n",
    "min_conv_units = [\"  'Huntstown'\", \"     'PBEGG6'\", \"   'AGH_CCGT'\", \"Knockfinglas\"]\n",
    "total_min_gas_max_mw = net.gen.loc[(net.gen['type'] == 9) & (net.gen['name'].isin(min_conv_units)), 'max_p_mw'].sum()\n",
    "mask_gas = (net.gen['type'].isin(gas_types)) & (net.gen['in_service'] == True)\n",
    "all_gas_pw_max = net.gen.loc[mask_gas, 'max_p_mw'].sum()\n",
    "mask_offshore = (net.gen['type'] == 16) & (net.gen['in_service'] == True)\n",
    "all_offshore_max_pw_re = net.gen.loc[mask_offshore, 'max_p_mw'].sum()\n",
    "mask_wind = (net.gen['type'].isin(wind_types)) & (net.gen['in_service'] == True)\n",
    "all_onshore_max_pw_re = net.gen.loc[mask_wind, 'max_p_mw'].sum()\n",
    "mask_solar = (net.gen['type'].isin(solar_types)) & (net.gen['in_service'] == True)\n",
    "all_solar_max_pw_re = net.gen.loc[mask_solar, 'max_p_mw'].sum()\n",
    "mask_storage = (net.gen['type'].isin(storage_types)) & (net.gen['in_service'] == True)\n",
    "all_storage_max_pw_re = net.gen.loc[mask_storage, 'max_p_mw'].sum()\n",
    "mask_interconnector = (net.gen['type'].isin(interconnector_type)) & (net.gen['in_service'] == True)\n",
    "all_interconnector_max_pw_re = net.gen.loc[mask_interconnector, 'max_p_mw'].sum()\n",
    "mask_all_re = (net.gen['type'].isin(all_re_types)) & (net.gen['in_service'] == True)\n",
    "total_re_max_pw = all_solar_max_pw_re + mask_offshore + mask_wind\n",
    "\n",
    "#Status of generation\n",
    "print(f\"total conv generation at script begin: {all_gas_pw_max}, percentage of total: {(all_gas_pw_max/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "print(f\"total offshore generation at script begin: {all_offshore_max_pw_re}, percentage of total: {(all_offshore_max_pw_re/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "print(f\"total onshore generation at script begin: {all_onshore_max_pw_re}, percentage of total: {(all_onshore_max_pw_re/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "print(f\"total solar generation at script begin: {all_solar_max_pw_re}, percentage of total: {(all_solar_max_pw_re/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "print(f\"total storage generation at script begin: {all_storage_max_pw_re}, percentage of total: {(all_storage_max_pw_re/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "print(f\"total interconnector generation at script begin: {all_interconnector_max_pw_re}, percentage of total: {(all_interconnector_max_pw_re/(net.gen.loc[net.gen['in_service'] == True,'max_p_mw'].sum()))*100}\")\n",
    "\n",
    "#Status of load\n",
    "total_load = net.load.loc[net.load['in_service'] == True,'p_mw'].sum()\n",
    "print(f\"total pw load: {total_load}\")\n",
    "\n",
    "#Save network file to pickle for use\n",
    "pp.to_pickle(net,\"adjusted_network.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff099028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage total MW: -4689.60\n",
      "Gap before RE: 11388.33 MW\n",
      "Existing solar: 0.0\n",
      "Existing wind: 0.0\n",
      "Remaining gap: 11388.329999999998\n",
      "Remaining gap after adding solar and wind: 11388.329999999998\n",
      "Leftover after s and w allocation: 3291.945129994998\n",
      "Existing solar: 8039.160000000001\n",
      "Existing wind: 57.224870005\n",
      "Solar CF achieved: 0.900 / 0.900\n",
      "Wind   CF achieved: 0.005 / 0.005\n",
      "Gap after RE      : 3291.95 MW\n",
      "To dispatch for conventional: 1125.2475\n",
      "Min gas gens set to max dispatch, new remaining gap: 2330.238491537196\n",
      "remaining gap persists after maxing out min conv gens, activating all gas gens\n",
      "remaining gap after all gas turned to min_p_mw: 2304.0951299949993\n",
      "remaining gap persists after activating all gas gens, adding proportional generation\n",
      "Final remaining gap: 0.00 MW\n",
      "Total load: 5849.02 MW, total generation: 5849.02 MW\n"
     ]
    }
   ],
   "source": [
    "# ─── User inputs ───────────────────────────────────────────────────────────────\n",
    "maximize_solar = 0.9\n",
    "maximize_wind  = 0.005   # give the “other” technology at least 5%\n",
    "Bess_CF        = -1     # no storage dispatch if negative\n",
    "tol            = 1e-2   # MW tolerance\n",
    "season         = \"summer\" #choose \"summer\" or \"winter\" for ratings and SP or WP demand\n",
    "overshoot      = 0    # XXX margin in MW, attempt to get wind dominant dispatches to converge\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "net = pp.from_pickle(\"adjusted_network.p\")\n",
    "total_load += overshoot\n",
    "# --- Build masks---\n",
    "mask_gas       = net.gen['type'].isin(gas_types) & net.gen['in_service']\n",
    "mask_min_conv  = net.gen['name'].isin(min_conv_units)\n",
    "mask_all_conv  = net.gen['type'].isin(gas_types)\n",
    "mask_storage   = (net.gen['type'] == 14) & net.gen['in_service']\n",
    "mask_intercon  = (net.gen['type'] == 49) & net.gen['in_service']\n",
    "mask_wind      = net.gen['type'].isin(all_wind_types) & net.gen['in_service']\n",
    "mask_offshore  = (net.gen['type'] == 16) & net.gen['in_service']\n",
    "mask_solar     = net.gen['type'].isin(solar_types) & net.gen['in_service']\n",
    "mask_all_re = net.gen['type'].isin(all_re_types) & net.gen['in_service']\n",
    "\n",
    "# season update\n",
    "if season == \"winter\":\n",
    "    print(f\"Season updated to winter\")\n",
    "    net.line['max_i_ka'] = net.line['wp_max_i_ka']\n",
    "    update_load_from_csv(net, load_df_WP)\n",
    "    total_load = net.load.loc[net.load['in_service'] == True,'p_mw'].sum()\n",
    "    total_load += overshoot\n",
    "\n",
    "# capacities\n",
    "solar_cap = net.gen.loc[mask_solar,  'max_p_mw'].sum()\n",
    "wind_cap  = net.gen.loc[mask_wind,   'max_p_mw'].sum()\n",
    "\n",
    "# ---Dispatch must-runs ---\n",
    "# disable all gas, then turn on minimum conv units at their min_p_mw\n",
    "net.gen.loc[mask_all_conv,      'in_service'] = False\n",
    "net.gen.loc[mask_min_conv, 'in_service'] = True\n",
    "net.gen.loc[mask_min_conv, 'p_mw']       = net.gen.loc[mask_min_conv, 'min_p_mw']\n",
    "\n",
    "# storage\n",
    "net.gen.loc[mask_storage, 'p_mw'] = net.gen.loc[mask_storage, 'max_p_mw'] * Bess_CF\n",
    "\n",
    "# interconnectors\n",
    "net.gen.loc[mask_intercon, 'p_mw'] = net.gen.loc[mask_intercon, 'min_p_mw']\n",
    "\n",
    "#Debug\n",
    "print(f\"Storage total MW: {net.gen.loc[mask_storage, 'p_mw'].sum():.2f}\")\n",
    "\n",
    "# --- Compute remaining gap after must-runs ---\n",
    "remaining_gap = total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()\n",
    "print(f\"Gap before RE: {remaining_gap:.2f} MW\")\n",
    "\n",
    "# --- Zero-out renewables from any prior run ---\n",
    "net.gen.loc[mask_solar, 'p_mw'] = 0.0\n",
    "net.gen.loc[mask_wind,  'p_mw'] = 0.0\n",
    "\n",
    "def dispatch_gens(remaining_gap,carry_over = 0):\n",
    "    # --- Compute absolute CF caps (MW) ---\n",
    "    cap_s = solar_cap * maximize_solar\n",
    "    cap_w = wind_cap  * maximize_wind\n",
    "    #debug\n",
    "    print(f\"Existing solar: {net.gen.loc[mask_solar, 'p_mw'].sum()}\")\n",
    "    print(f\"Existing wind: {net.gen.loc[mask_wind, 'p_mw'].sum()}\")\n",
    "    print(f\"Remaining gap: {remaining_gap}\")\n",
    "    remaining_gap += net.gen.loc[mask_solar, 'p_mw'].sum() + net.gen.loc[mask_wind,  'p_mw'].sum()\n",
    "    print(f\"Remaining gap after adding solar and wind: {remaining_gap}\")\n",
    "    net.gen.loc[mask_solar, 'p_mw'] = 0.0\n",
    "    net.gen.loc[mask_wind,  'p_mw'] = 0.0\n",
    "\n",
    "    # --- One-shot RE allocation (proportional → pour-over) ---\n",
    "    s_alloc = w_alloc = 0.0\n",
    "    if remaining_gap > tol:\n",
    "        total_cap = cap_s + cap_w\n",
    "        # proportional split\n",
    "        s_alloc = min(cap_s, remaining_gap * cap_s/total_cap)\n",
    "        w_alloc = min(cap_w, remaining_gap * cap_w/total_cap)\n",
    "        leftover = remaining_gap - (s_alloc + w_alloc)\n",
    "        #debug\n",
    "        print(f\"Leftover after s and w allocation: {leftover}\")\n",
    "\n",
    "        # pour any leftover into the technology that still has headroom\n",
    "        if leftover > tol:\n",
    "            if s_alloc >= cap_s and w_alloc < cap_w:\n",
    "                w_alloc += min(cap_w - w_alloc, leftover)\n",
    "            elif w_alloc >= cap_w and s_alloc < cap_s:\n",
    "                s_alloc += min(cap_s - s_alloc, leftover)\n",
    "\n",
    "        # write back\n",
    "        net.gen.loc[mask_solar, 'p_mw'] = (\n",
    "            (net.gen.loc[mask_solar, 'max_p_mw'] * (s_alloc / solar_cap))\n",
    "        )\n",
    "        net.gen.loc[mask_wind,  'p_mw'] = (\n",
    "            (net.gen.loc[mask_wind,  'max_p_mw'] * (w_alloc / wind_cap))\n",
    "        )\n",
    "    \n",
    "        #debug\n",
    "        print(f\"Existing solar: {net.gen.loc[mask_solar, 'p_mw'].sum()}\")\n",
    "        print(f\"Existing wind: {net.gen.loc[mask_wind, 'p_mw'].sum()}\")\n",
    "        remaining_gap = total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()\n",
    "\n",
    "    achieved_solar_cf = s_alloc / solar_cap if solar_cap else 0.0\n",
    "    achieved_wind_cf  = w_alloc / wind_cap  if wind_cap  else 0.0\n",
    "\n",
    "    print(f\"Solar CF achieved: {(net.gen.loc[mask_solar, 'p_mw'].sum()/net.gen.loc[mask_solar, 'max_p_mw'].sum()):.3f} / {maximize_solar:.3f}\")\n",
    "    print(f\"Wind   CF achieved: {(net.gen.loc[mask_wind, 'p_mw'].sum()/net.gen.loc[mask_wind, 'max_p_mw'].sum()):.3f} / {maximize_wind:.3f}\")\n",
    "    print(f\"Gap after RE      : {remaining_gap:.2f} MW\")\n",
    "\n",
    "    # --- Dispatch gas into remaining gap ---\n",
    "    if remaining_gap > tol or leftover > tol:\n",
    "        remaining_gap = max(remaining_gap,leftover)\n",
    "        # Ramp “min_conv” units from their current p_mw up to max_p_mw\n",
    "        headroom = net.gen.loc[mask_min_conv, 'max_p_mw'] - net.gen.loc[mask_min_conv, 'p_mw']\n",
    "        total_head = headroom.sum()\n",
    "        to_dispatch = min(remaining_gap, total_head)\n",
    "        if total_head > 0:\n",
    "            #need to proportionally distribute\n",
    "            #debug\n",
    "            print(f\"To dispatch for conventional: {to_dispatch}\")\n",
    "            net.gen.loc[mask_min_conv, 'p_mw'] = np.minimum(net.gen.loc[mask_min_conv, 'p_mw']+((net.gen.loc[mask_min_conv, 'max_p_mw']/(net.gen.loc[mask_min_conv, 'max_p_mw'].sum()))*to_dispatch),net.gen.loc[mask_min_conv, 'max_p_mw'])\n",
    "            remaining_gap = ((total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()))+carry_over\n",
    "            print(f\"Min gas gens set to max dispatch, new remaining gap: {remaining_gap}\")\n",
    "\n",
    "        # If still a gap, turn on all other gas units at their min_p_mw\n",
    "        if remaining_gap > tol:\n",
    "            print(f\"remaining gap persists after maxing out min conv gens, activating all gas gens\")\n",
    "            net.gen.loc[mask_all_conv, 'in_service'] = True\n",
    "            net.gen.loc[mask_all_conv, 'p_mw']       = net.gen.loc[mask_all_conv, 'min_p_mw']\n",
    "            remaining_gap = (total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()) + carry_over\n",
    "            print(f\"remaining gap after all gas turned to min_p_mw: {remaining_gap}\")\n",
    "\n",
    "        # If still a gap, turn on all gas units up proportionally\n",
    "        if remaining_gap > tol:\n",
    "            print(f\"remaining gap persists after activating all gas gens, adding proportional generation\")\n",
    "            headroom = net.gen.loc[mask_all_conv, 'max_p_mw'] - net.gen.loc[mask_all_conv, 'p_mw']\n",
    "            total_head = headroom.sum()\n",
    "            to_dispatch = min(remaining_gap, total_head)\n",
    "            if total_head > 0:\n",
    "                #need to proportionally distribute\n",
    "                net.gen.loc[mask_all_conv, 'p_mw'] = np.minimum(net.gen.loc[mask_all_conv, 'p_mw']+((net.gen.loc[mask_all_conv, 'max_p_mw']/(net.gen.loc[mask_all_conv, 'max_p_mw'].sum()))*to_dispatch),net.gen.loc[mask_all_conv, 'max_p_mw'])\n",
    "                remaining_gap = (total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()) + carry_over\n",
    "\n",
    "        # If overshoot (remaining_gap < 0), pull back on renewables (detailed edits can allow for user to turn off gas gens to avoid this)\n",
    "        if remaining_gap < -tol:\n",
    "            print(f\"Overshot remaining_gap adjustment, remaining gap: {remaining_gap} tapering renewables to adjust\")\n",
    "            total_re = net.gen.loc[mask_all_re, 'p_mw'].sum()\n",
    "            reduction = max(remaining_gap, -total_re)\n",
    "            net.gen.loc[mask_all_re, 'p_mw'] = np.maximum(net.gen.loc[mask_all_re, 'p_mw']+((net.gen.loc[mask_all_re, 'p_mw']/(net.gen.loc[mask_all_re, 'p_mw'].sum()))*reduction),0)\n",
    "            remaining_gap = (total_load - net.gen.loc[net.gen['in_service'], 'p_mw'].sum()) + carry_over\n",
    "            print(f\"Solar CF achieved after reduction: {(net.gen.loc[mask_solar, 'p_mw'].sum()/net.gen.loc[mask_solar, 'max_p_mw'].sum()):.3f} / {maximize_solar:.3f}\")\n",
    "            print(f\"Wind   CF achieved after reduction: {(net.gen.loc[mask_wind, 'p_mw'].sum()/net.gen.loc[mask_wind, 'max_p_mw'].sum()):.3f} / {maximize_wind:.3f}\")\n",
    "        \n",
    "    return remaining_gap, carry_over\n",
    "remaining_gap, carry_over = dispatch_gens(remaining_gap)\n",
    "print(f\"Final remaining gap: {remaining_gap:.2f} MW\")\n",
    "\n",
    "# --- Overall check ---\n",
    "total_gen = net.gen.loc[net.gen['in_service'], 'p_mw'].sum()\n",
    "print(f\"Total load: {total_load:.2f} MW, total generation: {total_gen:.2f} MW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf372fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Load: 5849.0199999999995 MW, Total Generation: 5849.019999999999 MW\n",
      "Power flow calculation successful with dc start and nr algorithm, with q lims set to True\n",
      "Slack = 375.49 MW\n",
      "Convergence not achieved: Slack: 375.49343893972764 MW\n",
      "Existing solar: 8039.160000000001\n",
      "Existing wind: 57.224870005\n",
      "Remaining gap: 375.49343893972764\n",
      "Remaining gap after adding solar and wind: 8471.878308944728\n",
      "Leftover after s and w allocation: 375.49343893972764\n",
      "Existing solar: 8039.160000000001\n",
      "Existing wind: 57.224870005\n",
      "Solar CF achieved: 0.900 / 0.900\n",
      "Wind   CF achieved: 0.005 / 0.005\n",
      "Gap after RE      : 0.00 MW\n",
      "To dispatch for conventional: 375.49343893972764\n",
      "Min gas gens set to max dispatch, new remaining gap: 44.814955259153066\n",
      "remaining gap persists after maxing out min conv gens, activating all gas gens\n",
      "remaining gap after all gas turned to min_p_mw: 2679.588568934727\n",
      "remaining gap persists after activating all gas gens, adding proportional generation\n",
      "Total Load: 5849.0199999999995 MW, Total Generation: 6224.513438939727 MW\n",
      "Power flow calculation successful with dc start and nr algorithm, with q lims set to True\n",
      "Slack = -4.67 MW\n",
      "Convergence achieved: Slack within target range.\n"
     ]
    }
   ],
   "source": [
    "# Define power flow attempts as a list of tuples (initialization method, algorithm)\n",
    "power_flow_attempts = [\n",
    "    #('flat', 'nr', True),   # Newton-Raphson with flat start, qlims set to true\n",
    "    #('flat', 'nr', False),  # Newton-Raphson with flat start, qlims set to false\n",
    "    ('dc', 'nr', True),     # Newton-Raphson with DC start, qlims set to true (most likely to solve using this)\n",
    "    #('dc', 'nr', False),    # Newton-Raphson with DC start, qlims set to false\n",
    "]\n",
    "\n",
    "pf_settings = {\n",
    "    \"algorithm\": 'nr',\n",
    "    \"max_iteration\": 100,\n",
    "    \"tolerance_mva\": 1e-5,\n",
    "    \"init\": 'dc',\n",
    "    \"enforce_q_lims\": True,\n",
    "    \"calculate_voltage_angles\": True,\n",
    "    \"logging\": False,\n",
    "    \"voltage_depend_loads\": False,\n",
    "    \"v_debug\": True\n",
    "}\n",
    "\n",
    "slack_tol = 40          # MW tolerance for slack generator output (Turlough hill equivilant of all four gens into 1, 10 MW per gen seen as reasonable)\n",
    "slack = 1000\n",
    "def attempt_power_flow(net, attempts=1):\n",
    "    # Below is to display generation vs load balance for ROI\n",
    "    total_load = net.load.p_mw.sum()\n",
    "    total_generation = net.gen.loc[net.gen['in_service'] == True, 'p_mw'].sum()\n",
    "    print(f\"Total Load: {total_load} MW, Total Generation: {total_generation} MW\")\n",
    "    \n",
    "    for init_method, algorithm, q_lims in attempts:\n",
    "        try:\n",
    "            pp.runpp(net, init=init_method, max_iteration=100, calculate_voltage_angles=True,\n",
    "                     enforce_q_lims=q_lims, tolerance_mva=5e-3, algorithm=algorithm, logging=False,\n",
    "                     voltage_depend_loads=False, v_debug=True)\n",
    "            if net.converged:\n",
    "                print(f\"Power flow calculation successful with {init_method} start and {algorithm} algorithm, with q lims set to {q_lims}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"Power flow did not converge, checking mismatches...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Power flow calculation failed for {init_method} start {algorithm}, with q lims set to {q_lims}: {e}\")\n",
    "            #Below optional to see diagnostic if powerflow fails to converge\n",
    "            #diagnostic_results = pp.diagnostic(net, report_style='detailed')\n",
    "            #print(diagnostic_results)\n",
    "    return False\n",
    "\n",
    "def compute_slack(net):\n",
    "    slack_indices = net.gen.index[net.gen.slack == True]\n",
    "    total_slack = sum(net.res_gen.at[idx, \"p_mw\"] for idx in slack_indices)\n",
    "    return total_slack\n",
    "\n",
    "while abs(slack) > slack_tol:\n",
    "    if attempt_power_flow(net,power_flow_attempts):\n",
    "        slack = compute_slack(net)\n",
    "        print(f\"Slack = {slack:.2f} MW\")\n",
    "        gap = slack\n",
    "        if abs(slack) <= slack_tol:\n",
    "            print(\"Convergence achieved: Slack within target range.\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Convergence not achieved: Slack: {slack} MW\")\n",
    "            remaining_gap = slack\n",
    "            carry_over = slack\n",
    "            remaining_gap,carry_over = dispatch_gens(remaining_gap,carry_over)\n",
    "    else:\n",
    "        print(f\"Power flow failed to solve\")\n",
    "\n",
    "    \n",
    "#Save network file to pickle for use\n",
    "pp.to_pickle(net,\"adjusted_network.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9caf140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered contingency analysis results have been saved to 'Results/Contingency/contingency_results_filtered_14052025.csv'.\n",
      "Line with HIGHEST max loading:  'Derrycarney' to    'Derrinlough' (222.7%)Caused by:  'Portlaoise' to  'Kilcormac'\n",
      "Line with LOWEST  max loading: Seven Hills to Ballygar (0.0%)Caused by:    Offshore  to   'Knockraha'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandapower.plotting  # registers the bus_geodata accessor\n",
    "#Filter 110 kV+ buses with valid geodata for easier plotting\n",
    "filtered_buses = net.bus[\n",
    "    (net.bus['vn_kv'] >= 110)\n",
    "    & net.bus['geodata'].notna()\n",
    "    & net.bus['geodata'].apply(lambda x: x != (0, 0))\n",
    "]\n",
    "bus_ids = filtered_buses.index.tolist()\n",
    "\n",
    "net_cont = copy.deepcopy(net) # Needed because contingency analysis needs reindexed buses due to out of service elements\n",
    "# Load the bus names mapping\n",
    "bus_idx_to_name = dict(zip(net_cont.bus['index'], net_cont.bus['bus_names']))\n",
    "# Identify all buses that are not in service\n",
    "inactive_buses = net_cont.bus[net_cont.bus['in_service'] == False].index.tolist()\n",
    "\n",
    "# Drop all those inactive buses (and associated elements)\n",
    "pp.drop_buses(net_cont, inactive_buses, drop_elements=True)\n",
    "\n",
    "# Ensure that bus_geodata only contains buses that are present in the bus table\n",
    "# if bus_geodata doesn’t exist, create an empty one\n",
    "if not hasattr(net_cont, \"bus_geodata\"):\n",
    "    net_cont.bus_geodata = pd.DataFrame(index=net_cont.bus.index)\n",
    "else:\n",
    "    # otherwise filter down to only existing buses\n",
    "    net_cont.bus_geodata = net_cont.bus_geodata.loc[\n",
    "        net_cont.bus_geodata.index.isin(net_cont.bus.index)\n",
    "    ]\n",
    "net_cont.bus_geodata = net_cont.bus_geodata[net_cont.bus_geodata.index.isin(net_cont.bus.index)]\n",
    "# Now safely call create_continuous_bus_index\n",
    "pp.create_continuous_bus_index(net_cont, start=0, store_old_index=False)\n",
    "# Identify high-voltage buses (>=110 kV)\n",
    "high_voltage_buses = net_cont.bus[net_cont.bus['vn_kv'] >= 110].index\n",
    "\n",
    "# Define contingency cases for lines and transformers\n",
    "high_voltage_long_lines = net_cont.line[\n",
    "    (net_cont.line['from_bus'].isin(high_voltage_buses) | net_cont.line['to_bus'].isin(high_voltage_buses)) &\n",
    "    (net_cont.line['length_km'] >= 1.1)\n",
    "]\n",
    "\n",
    "transformer_contingencies = net_cont.trafo[\n",
    "    net_cont.trafo['hv_bus'].isin(high_voltage_buses) | net_cont.trafo['lv_bus'].isin(high_voltage_buses)\n",
    "]\n",
    "\n",
    "contingency_cases = {\n",
    "    \"line\": {\"index\": high_voltage_long_lines.index.tolist()},\n",
    "    \"trafo\": {\"index\": transformer_contingencies.index.tolist()}\n",
    "}    \n",
    "\n",
    "# Run the contingency analysis with the defined settings\n",
    "try:\n",
    "    pp.contingency.run_contingency_ls2g(net_cont, contingency_cases, pp.runpp, **pf_settings)\n",
    "except Exception as e:\n",
    "    print(f\"ERROR - during contingency analysis: {e}\")\n",
    "    #optional error handling\n",
    "    diagnostic_results = pp.diagnostic(net_cont, report_style='detailed')\n",
    "    print(diagnostic_results)\n",
    "\n",
    "# Prepare a DataFrame for processing the results\n",
    "contingency_output = pd.DataFrame()\n",
    "\n",
    "# Filter the results to include only elements in the contingency cases\n",
    "res_line_filtered = net_cont.res_line.loc[high_voltage_long_lines.index]\n",
    "res_trafo_filtered = net_cont.res_trafo.loc[transformer_contingencies.index]\n",
    "\n",
    "# Ensure the line_data index is properly set\n",
    "if net_cont.line.index.name != 'line_id':\n",
    "    net_cont.line.set_index('line_id', inplace=True)\n",
    "\n",
    "# Reset index if necessary for joining\n",
    "if 'index' not in res_line_filtered.columns:\n",
    "    res_line_filtered.reset_index(inplace=True)\n",
    "\n",
    "# Join line names with contingency results\n",
    "res_line_filtered = res_line_filtered.join(net_cont.line['name'], on='index')\n",
    "\n",
    "# Prepare elements to process\n",
    "elements_to_process = [(\"line\", res_line_filtered), (\"trafo\", res_trafo_filtered)]\n",
    "\n",
    "for element_type, elements in elements_to_process:\n",
    "    # Skip processing if elements DataFrame is empty\n",
    "    if elements.empty:\n",
    "        continue\n",
    "\n",
    "    for idx, row in elements.iterrows():\n",
    "        cause_element = row.get('cause_element', 'Unknown')\n",
    "        cause_index = row.get('cause_index', 'Unknown')\n",
    "        max_loading_percent = row.get('max_loading_percent', 'N/A')\n",
    "        intact_loading_percent = row.get('loading_percent', 'N/A')\n",
    "        element_name = row.get('name', 'Unknown')\n",
    "\n",
    "        # Get the cause element name\n",
    "        if cause_element in net_cont and cause_index in net_cont[cause_element].index:\n",
    "            cause_element_name = net_cont[cause_element].at[cause_index, 'name']\n",
    "        else:\n",
    "            cause_element_name = 'Unknown'\n",
    "\n",
    "        # Append data to the contingency output DataFrame\n",
    "        new_data = {\n",
    "            \"Element Type\": element_type,\n",
    "            \"Element Index\": idx,\n",
    "            \"Element Name\": element_name,\n",
    "            \"Intact Loading %\": intact_loading_percent,\n",
    "            \"Max Loading %\": max_loading_percent,\n",
    "            \"Cause Element\": cause_element,\n",
    "            \"Cause Index\": cause_index,\n",
    "            \"Cause Element Name\": cause_element_name\n",
    "        }\n",
    "        # Update: Use pd.concat instead of append\n",
    "        contingency_output = pd.concat([contingency_output, pd.DataFrame([new_data])], ignore_index=True)\n",
    "\n",
    "if hasattr(net_cont.res_bus, \"min_vm_pu\"):\n",
    "    # If run_contingency_ls2g stored cause info in res_bus, handle it\n",
    "    pass\n",
    "else:\n",
    "    # If not, fill them as 'Unknown'\n",
    "    net_cont.res_bus[\"cause_element\"] = \"Unknown\"\n",
    "    net_cont.res_bus[\"cause_index\"]   = \"Unknown\"\n",
    "\n",
    "# create a DataFrame with relevant columns\n",
    "bus_results = net_cont.res_bus.copy()\n",
    "bus_results[\"bus_idx\"] = bus_results.index\n",
    "\n",
    "# align nominal voltage\n",
    "bus_results[\"vn_kv\"] = net_cont.bus[\"vn_kv\"].reindex(bus_results.index)\n",
    "# keep only buses ≥110 kV\n",
    "bus_results = bus_results[bus_results[\"vn_kv\"] >= 110]\n",
    "\n",
    "bus_results[\"bus_name\"] = bus_results[\"bus_idx\"].map(lambda b: bus_idx_to_name.get(b, f\"Bus_{b}\"))\n",
    "\n",
    "for idx, row in bus_results.iterrows():\n",
    "    vm_pu = row[\"vm_pu\"]\n",
    "    max_vm_pu = row[\"max_vm_pu\"]\n",
    "    min_vm_pu = row[\"min_vm_pu\"]\n",
    "    bus_name = row[\"bus_name\"]\n",
    "    #Below reflects standard operation in Irish system, voltages must stay within +/-10% and so must the voltage magnitude step after contingency\n",
    "    if not (0.9 <= min_vm_pu or max_vm_pu <= 1.1 or max_vm_pu-vm_pu<=0.1 or vm_pu-min_vm_pu<=0.1):\n",
    "        # If it's outside 0.90-1.10 p.u., record a violation\n",
    "        print(\"Voltage violation detected, review contingency results\")\n",
    "        new_data = {\n",
    "            \"Element Type\": \"bus\",\n",
    "            \"Element Index\": idx,\n",
    "            \"Element Name\": bus_name,\n",
    "            \"Voltage [p.u.]\": vm_pu,\n",
    "            \"Max Voltage [p.u.]\": max_vm_pu,\n",
    "            \"Min Voltage [p.u.]\": min_vm_pu,\n",
    "            #\"Cause Element\": cause_element,\n",
    "            #\"Cause Index\": cause_index,\n",
    "            # We can store if it's Over/Under\n",
    "            \"Violation Type\": \"Under-Voltage\" if min_vm_pu < 0.9 else \"Over-Voltage\"\n",
    "        }\n",
    "        contingency_output = pd.concat([contingency_output, pd.DataFrame([new_data])], ignore_index=True)\n",
    "\n",
    "# Save contingency results to CSV, optional\n",
    "contingency_output.to_csv(f\"Results/Contingency/contingency_results_filtered_S{maximize_solar}_W{maximize_wind}.csv\", index=False)\n",
    "print(f\"Filtered contingency analysis results have been saved to 'Results/Contingency/contingency_results_filtered_14052025.csv'.\")\n",
    "\n",
    "\n",
    "# select only line‐type contingencies, edit or add new code for transformer contingencies\n",
    "line_cont = contingency_output[contingency_output['Element Type'] == 'line']\n",
    "\n",
    "if not line_cont.empty:\n",
    "    # find the index of the max/min “Max Loading %”\n",
    "    idx_max = line_cont['Max Loading %'].idxmax()\n",
    "    idx_min = line_cont['Max Loading %'].idxmin()\n",
    "\n",
    "    max_row = line_cont.loc[idx_max]\n",
    "    min_row = line_cont.loc[idx_min]\n",
    "\n",
    "    print(f\"Line with HIGHEST max loading: {max_row['Element Name']} \"\n",
    "          f\"({max_row['Max Loading %']:.1f}%)\"\n",
    "         f\"Caused by: {max_row['Cause Element Name']}\")\n",
    "    print(f\"Line with LOWEST  max loading: {min_row['Element Name']} \"\n",
    "          f\"({min_row['Max Loading %']:.1f}%)\"\n",
    "         f\"Caused by: {min_row['Cause Element Name']}\")\n",
    "else:\n",
    "    print(\"No line contingencies found in results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_cont exists? True\n"
     ]
    }
   ],
   "source": [
    "from numba import njit, prange\n",
    "from pandapower.pypower.makeBdc import makeBdc\n",
    "from pandapower.pypower.makeLODF import makeLODF, makeOTDF\n",
    "import time\n",
    "# - - - - - - User defined thresholds - - - - - \n",
    "OVERLOAD_THRESHOLD = 110  # not in per unit (1.0 means 100% loading)\n",
    "OTDF_filter = 0.01 # filter out OTDF values that are less than this value or greater than this negative value\n",
    "net = pp.from_pickle(\"adjusted_network.p\")\n",
    "# - - - - - - - - - - - - - - --- - - - - - - - \n",
    "def normalize_line_name(line_name):\n",
    "    return ' '.join(line_name.strip().split())\n",
    "\n",
    "def preprocess_network(net):\n",
    "    \"\"\"\n",
    "    Normalize line/trafo names and ensure consistent bus indexing in pandapower.\n",
    "    \"\"\"\n",
    "    if \"name_normalized\" not in net.line.columns:\n",
    "        net.line[\"name_normalized\"] = net.line[\"name\"].apply(normalize_line_name)\n",
    "    if \"name_normalized\" not in net.trafo.columns:\n",
    "        net.trafo[\"name_normalized\"] = net.trafo[\"name\"].apply(normalize_line_name)\n",
    "    if \"from_bus_orig\" not in net.line.columns:\n",
    "        net.line[\"from_bus_orig\"] = net.line[\"from_bus\"]\n",
    "    if \"to_bus_orig\" not in net.line.columns:\n",
    "        net.line[\"to_bus_orig\"] = net.line[\"to_bus\"]\n",
    "    pp.create_continuous_bus_index(net, start=0, store_old_index=True)\n",
    "\n",
    "def orient_lines_by_flow(net):\n",
    "    \"\"\"\n",
    "    Runs a DC power flow, then re-orients each line if its flow is negative.\n",
    "    Re-runs DC to update flows.\n",
    "    \"\"\"\n",
    "    pp.runpp(net, **pf_settings)\n",
    "    for i in net.line.index:\n",
    "        p_from = net.res_line.at[i, \"p_from_mw\"]\n",
    "        if p_from < 0:\n",
    "            old_from = net.line.at[i, \"from_bus\"]\n",
    "            old_to   = net.line.at[i, \"to_bus\"]\n",
    "            net.line.at[i, \"from_bus\"] = old_to\n",
    "            net.line.at[i, \"to_bus\"]   = old_from\n",
    "    pp.runpp(net, **pf_settings)\n",
    "\n",
    "def map_branch_indices(net, orig_branch_idx):\n",
    "    \"\"\"\n",
    "    Map each HV branch in the subnetwork to its original pandapower index.\n",
    "    For lines, return the net.line index; for transformers, return the net.trafo index.\n",
    "    Also returns a list indicating branch type (\"line\", \"trafo\", or \"unknown\").\n",
    "    \"\"\"\n",
    "    branch_lookup = net._pd2ppc_lookups[\"branch\"]\n",
    "    line_range = branch_lookup.get(\"line\", (0, 0))\n",
    "    line_start, line_end = line_range\n",
    "    net_line_indices = net.line.index.to_numpy()\n",
    "    \n",
    "    trafo_range = branch_lookup.get(\"trafo\", None)\n",
    "    if trafo_range is not None:\n",
    "        trafo_start, trafo_end = trafo_range\n",
    "        net_trafo_indices = net.trafo.index.to_numpy()\n",
    "    else:\n",
    "        trafo_start, trafo_end = (0, 0)\n",
    "        net_trafo_indices = np.array([])\n",
    "    \n",
    "    mapped = np.full(len(orig_branch_idx), -1, dtype=int)\n",
    "    mapped_type = [\"\" for _ in range(len(orig_branch_idx))]\n",
    "    for idx, ppc_idx in enumerate(orig_branch_idx):\n",
    "        if line_start <= ppc_idx < line_end:\n",
    "            mapped[idx] = net_line_indices[ppc_idx - line_start]\n",
    "            mapped_type[idx] = \"line\"\n",
    "        elif trafo_range is not None and trafo_start <= ppc_idx < trafo_end:\n",
    "            mapped[idx] = net_trafo_indices[ppc_idx - trafo_start]\n",
    "            mapped_type[idx] = \"trafo\"\n",
    "        else:\n",
    "            mapped[idx] = -1\n",
    "            mapped_type[idx] = \"unknown\"\n",
    "    return mapped, mapped_type\n",
    "\n",
    "def compute_base_loading_vectorized(net, branch_array, orig_branch_idx):\n",
    "    \"\"\"\n",
    "    Vectorized computation of base loading for each branch.\n",
    "    For lines, use net.line[\"max_i_ka\"]; for transformers, use net.trafo[\"sn_mva\"].\n",
    "    Converts DataFrame indices to positional indices.\n",
    "    \"\"\"\n",
    "    mapped_branch_idx, mapped_type = map_branch_indices(net, orig_branch_idx)\n",
    "    mapped_type = np.array(mapped_type)\n",
    "    mapped_branch_idx = np.array(mapped_branch_idx)\n",
    "    n_br = branch_array.shape[0]\n",
    "    base_loading = np.zeros(n_br, dtype=float)\n",
    "    \n",
    "    line_positions = {idx: pos for pos, idx in enumerate(net.line.index)}\n",
    "    trafo_positions = {idx: pos for pos, idx in enumerate(net.trafo.index)}\n",
    "    \n",
    "    line_mask = (mapped_type == \"line\") & (mapped_branch_idx != -1)\n",
    "    if line_mask.any():\n",
    "        line_indices = np.array([line_positions[x] for x in mapped_branch_idx[line_mask]])\n",
    "        line_values = net.res_line[\"loading_percent\"].fillna(0.0).to_numpy()\n",
    "        base_loading[line_mask] = line_values[line_indices]\n",
    "    \n",
    "    trafo_mask = (mapped_type == \"trafo\") & (mapped_branch_idx != -1)\n",
    "    if trafo_mask.any():\n",
    "        trafo_indices = np.array([trafo_positions[x] for x in mapped_branch_idx[trafo_mask]])\n",
    "        trafo_values = net.res_trafo[\"loading_percent\"].fillna(0.0).to_numpy()\n",
    "        base_loading[trafo_mask] = (trafo_values[trafo_indices] * 1.25) / (OVERLOAD_THRESHOLD/100)  # Transformer allowed up to 125%\n",
    "    \n",
    "    return base_loading\n",
    "\n",
    "@njit(parallel=True)\n",
    "def clip_and_replace_parallel(matrix, clip_min, clip_max):\n",
    "    m, n = matrix.shape\n",
    "    for i in prange(m):\n",
    "        for j in range(n):\n",
    "            val = matrix[i, j]\n",
    "            if np.isnan(val):\n",
    "                matrix[i, j] = 0.0\n",
    "            elif val < clip_min:\n",
    "                matrix[i, j] = clip_min\n",
    "            elif val > clip_max:\n",
    "                matrix[i, j] = clip_max\n",
    "    return matrix\n",
    "\n",
    "def reindex_bus_ids(net, bus_array, branch_array):\n",
    "    \"\"\"\n",
    "    Re‐maps bus IDs in the ppc arrays to a contiguous 0..(n-1) range,\n",
    "    and returns mappings back to the *original* pandapower bus indices.\n",
    "    \"\"\"\n",
    "\n",
    "    if bus_array is None or branch_array is None or len(bus_array) == 0:\n",
    "        return bus_array, branch_array, {}, {}\n",
    "\n",
    "    #Grab the pandapower→ppc lookup, which may be a dict or a 1D np.array\n",
    "    pp_lookup = net._pd2ppc_lookups[\"bus\"]\n",
    "    if isinstance(pp_lookup, dict):\n",
    "        bus2ppc = pp_lookup\n",
    "    elif isinstance(pp_lookup, np.ndarray):\n",
    "        # array[pd_idx] = ppc_idx\n",
    "        bus2ppc = {pd_idx: int(ppc_idx) for pd_idx, ppc_idx in enumerate(pp_lookup)}\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type for pd2ppc bus lookup: {type(pp_lookup)}\")\n",
    "\n",
    "    #Invert it: ppc_idx → pandapower bus_idx\n",
    "    ppc_to_bus = {ppc: bus for bus, ppc in bus2ppc.items()}\n",
    "\n",
    "    #Pull the original ppc‐bus indices out of the first column of bus_array\n",
    "    old_ppc_ids = np.real(bus_array[:, 0]).astype(int)\n",
    "    old_bus_ids = np.array([ppc_to_bus.get(ppc, -1) for ppc in old_ppc_ids])\n",
    "\n",
    "    #Build your new 0..N-1 IDs\n",
    "    n_buses    = len(old_bus_ids)\n",
    "    new_ids    = np.arange(n_buses)\n",
    "    new_to_old = dict(zip(new_ids, old_bus_ids))\n",
    "    old_to_new = {old: new for new, old in new_to_old.items() if old >= 0}\n",
    "\n",
    "    #Overwrite bus_array’s first column with the new contiguous IDs\n",
    "    bus_array[:, 0] = new_ids\n",
    "\n",
    "    #Now update the branch_array’s from/to to use new IDs as well\n",
    "    from_b = np.real(branch_array[:, F_BUS]).astype(int)\n",
    "    to_b   = np.real(branch_array[:, T_BUS]).astype(int)\n",
    "    for i in range(len(branch_array)):\n",
    "        ppc_from = from_b[i]\n",
    "        ppc_to   = to_b[i]\n",
    "        old_from = ppc_to_bus.get(ppc_from, -1)\n",
    "        old_to   = ppc_to_bus.get(ppc_to,   -1)\n",
    "        branch_array[i, F_BUS] = old_to_new.get(old_from, -1)\n",
    "        branch_array[i, T_BUS] = old_to_new.get(old_to,   -1)\n",
    "\n",
    "    return bus_array, branch_array, new_to_old, old_to_new\n",
    "\n",
    "\n",
    "def build_hv_only_ppc(net):\n",
    "    \"\"\"\n",
    "    Runs AC power flow, orients lines, and extracts ppc arrays (bus, branch)\n",
    "    for HV buses (vn_kv >= 110) plus any slack buses.\n",
    "    Additionally excludes pandapower lines where length_km < 1.\n",
    "    Further filters to include only \"meshed\" HV buses.\n",
    "    \"\"\"\n",
    "    pp.runpp(net, **pf_settings)\n",
    "    \n",
    "    ppc = net._ppc\n",
    "    if \"bus\" not in ppc or \"branch\" not in ppc:\n",
    "        print(\"[Error] Missing ppc bus or branch.\")\n",
    "        return None, None, None\n",
    "\n",
    "    bus_array = ppc[\"bus\"].copy()\n",
    "    branch_array = ppc[\"branch\"].copy()\n",
    "\n",
    "    # Identify HV buses based on voltage (>= 110 kV)\n",
    "    hv_buses = net.bus[net.bus[\"vn_kv\"] >= 110].index.tolist()\n",
    "    slack_buses = net.gen[net.gen[\"slack\"] == True].bus.values\n",
    "    for sb in slack_buses:\n",
    "        if sb not in hv_buses:\n",
    "            hv_buses.append(sb)\n",
    "\n",
    "    # Filter to only \"meshed\" buses.\n",
    "    line_from = net.line[\"from_bus\"]\n",
    "    line_to   = net.line[\"to_bus\"]\n",
    "    mask_from = line_from.isin(hv_buses)\n",
    "    mask_to   = line_to.isin(hv_buses)\n",
    "    lines_in_hv = net.line[mask_from & mask_to]\n",
    "    line_connections = pd.concat([lines_in_hv[\"from_bus\"], lines_in_hv[\"to_bus\"]])\n",
    "    line_counts = line_connections.value_counts()\n",
    "\n",
    "    if \"trafo\" in net and not net.trafo.empty:\n",
    "        trafo_counts = net.trafo[\"hv_bus\"].value_counts()\n",
    "    else:\n",
    "        trafo_counts = pd.Series(dtype=float)\n",
    "\n",
    "    connectivity = line_counts.add(trafo_counts, fill_value=0)\n",
    "    meshed_hv_buses = [bus for bus in hv_buses if connectivity.get(bus, 0) >= 2]\n",
    "    hv_buses = meshed_hv_buses\n",
    "\n",
    "    bus_lookup = net._pd2ppc_lookups[\"bus\"]\n",
    "    hv_ppc_idx = [bus_lookup[b] for b in hv_buses if b in bus_lookup]\n",
    "\n",
    "    mask_bus = np.isin(bus_array[:, 0].astype(int), hv_ppc_idx)\n",
    "    bus_array = bus_array[mask_bus, :]\n",
    "\n",
    "    from_b = np.real(branch_array[:, F_BUS]).astype(int)\n",
    "    to_b   = np.real(branch_array[:, T_BUS]).astype(int)\n",
    "    mask_hv_br = np.isin(from_b, hv_ppc_idx) & np.isin(to_b, hv_ppc_idx)\n",
    "\n",
    "    line_start, line_end = net._pd2ppc_lookups[\"branch\"][\"line\"]\n",
    "    line_ppc_indices = range(line_start, line_end)\n",
    "    line_pp_indices  = net.line.index.tolist()\n",
    "    ppc_idx_to_line_idx = dict(zip(line_ppc_indices, line_pp_indices))\n",
    "    short_line_mask = (net.line[\"length_km\"] < 1.1)\n",
    "    short_line_idx = set(net.line[short_line_mask].index)\n",
    "    mask_short_line = np.zeros(branch_array.shape[0], dtype=bool)\n",
    "    for ppc_idx in line_ppc_indices:\n",
    "        if ppc_idx in ppc_idx_to_line_idx:\n",
    "            pandapower_line_idx = ppc_idx_to_line_idx[ppc_idx]\n",
    "            if pandapower_line_idx in short_line_idx:\n",
    "                mask_short_line[ppc_idx] = True\n",
    "\n",
    "    mask_br = mask_hv_br & (~mask_short_line)\n",
    "    orig_branch_idx = np.where(mask_br)[0]\n",
    "    branch_array = branch_array[mask_br, :]\n",
    "\n",
    "    return bus_array, branch_array, orig_branch_idx\n",
    "\n",
    "def compute_PTDF_LODF_OTDF(net):\n",
    "    \"\"\"\n",
    "    Builds an HV-only ppc subnetwork, reindexes bus IDs, then computes PTDF, LODF, and OTDF.\n",
    "    Returns (H, L, OTDF, bus_array, branch_array, new_to_old, orig_branch_idx, old_to_new).\n",
    "    \"\"\"\n",
    "    bus_array, branch_array, orig_branch_idx = build_hv_only_ppc(net)\n",
    "    if bus_array is None or branch_array is None or len(bus_array) == 0 or len(branch_array) == 0:\n",
    "        return None, None, None, None, None, None, None, None\n",
    "\n",
    "    bus_array, branch_array, new_to_old, old_to_new = reindex_bus_ids(net,bus_array, branch_array)\n",
    "    \n",
    "    Bbus, Bf, _, _, _ = makeBdc(bus_array, branch_array)\n",
    "    Bbus = Bbus.tocsc()\n",
    "    Bf   = Bf.tocsc()\n",
    "\n",
    "    reg_factor = 1e-4\n",
    "    Bbus_dense = Bbus.toarray() + reg_factor * np.eye(Bbus.shape[0])\n",
    "    try:\n",
    "        cond_num = np.linalg.cond(Bbus_dense)\n",
    "        if cond_num < 1e12:\n",
    "            invBbus = np.linalg.solve(Bbus_dense, np.eye(Bbus_dense.shape[0]))\n",
    "        else:\n",
    "            print(\"High condition number; using pseudoinverse.\")\n",
    "            invBbus = np.linalg.pinv(Bbus_dense, rcond=1e-6)\n",
    "    except LinAlgError as e:\n",
    "        print(f\"B matrix inversion error: {e}\")\n",
    "        invBbus = np.linalg.pinv(Bbus_dense, rcond=1e-6)\n",
    "    \n",
    "    PTDF_mat = Bf.dot(invBbus)\n",
    "    H = np.real(PTDF_mat)\n",
    "    H = clip_and_replace_parallel(H, -1, 1)\n",
    "    \n",
    "    L = makeLODF(branch_array, H)\n",
    "    L = np.real(L)\n",
    "    L = np.nan_to_num(L, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    \n",
    "    n_br = H.shape[0]\n",
    "    outage_branches = np.arange(n_br)\n",
    "    OTDF_raw = makeOTDF(H, L, outage_branches)\n",
    "    OTDF_raw = np.real(OTDF_raw)\n",
    "    OTDF_raw = np.nan_to_num(OTDF_raw, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    OTDF = clip_and_replace_parallel(OTDF_raw, -1e6, 1e6)\n",
    "    \n",
    "    return H, L, OTDF, bus_array, branch_array, new_to_old, orig_branch_idx, old_to_new\n",
    "\n",
    "batch_contingency = {}\n",
    "preprocess_network(net)\n",
    "orient_lines_by_flow(net)\n",
    "\n",
    "# Build debug dictionary for circuit info.\n",
    "circuit_info = {}\n",
    "for line_idx in net.line.index:\n",
    "    ln_name = net.line.at[line_idx, \"name\"]\n",
    "    fb_orig = net.line.at[line_idx, \"from_bus_orig\"]\n",
    "    tb_orig = net.line.at[line_idx, \"to_bus_orig\"]\n",
    "    circuit_info[line_idx] = f\"'{ln_name.strip()}'\"\n",
    "H, L, OTDF, topo_bus_array, topo_branch_array, new_to_old, orig_branch_idx, old_to_new = compute_PTDF_LODF_OTDF(net)\n",
    "n_br, n_bus = H.shape\n",
    "\n",
    "sample_new_to_old = new_to_old\n",
    "\n",
    "# Compute injection-dependent base loadings.\n",
    "base_loading = compute_base_loading_vectorized(net, topo_branch_array, orig_branch_idx)\n",
    "\n",
    "# Recalculate loading matrix with updated injections.\n",
    "loading_matrix = base_loading[:, None] + L * base_loading[None, :]\n",
    "loading_matrix = np.real(loading_matrix)\n",
    "\n",
    "# Map branches.\n",
    "mapped_branch_idx, mapped_type = map_branch_indices(net, orig_branch_idx)\n",
    "\n",
    "# Recompute max loading values.\n",
    "max_loading_values = loading_matrix.max(axis=1)\n",
    "max_loading_indices = loading_matrix.argmax(axis=1)\n",
    "\n",
    "line_idx_set  = set(net_cont.res_line.index)\n",
    "trafo_idx_set = set(net_cont.res_trafo.index)\n",
    "\n",
    "# Build per-file contingency data.\n",
    "cont_max = np.zeros(n_br)\n",
    "for j in range(n_br):\n",
    "    net_branch_idx = mapped_branch_idx[j]\n",
    "    branch_type = mapped_type[j]\n",
    "    if branch_type == \"line\" and net_branch_idx != -1:\n",
    "        branch_name = net.line.at[net_branch_idx, \"name\"]\n",
    "        intact_loading_pct = net.res_line.at[net_branch_idx, \"loading_percent\"]\n",
    "        max_ia_loading = net.line.at[net_branch_idx, \"max_i_ka\"]\n",
    "        if net_branch_idx in line_idx_set:\n",
    "            i_star = net_cont.res_line.at[net_branch_idx, \"cause_index\"]\n",
    "            max_loading_fraction = net_cont.res_line.at[net_branch_idx, \"max_loading_percent\"]\n",
    "            cont_max[j] = net_cont.res_line.at[net_branch_idx, \"max_loading_percent\"]\n",
    "        else:\n",
    "            i_star = -1\n",
    "            max_loading_fraction = intact_loading_pct\n",
    "            cont_max[j] = intact_loading_pct\n",
    "    elif branch_type == \"trafo\" and net_branch_idx != -1:\n",
    "        branch_name = net.trafo.at[net_branch_idx, \"name\"]\n",
    "        intact_loading_pct = net.res_trafo.at[net_branch_idx, \"loading_percent\"]\n",
    "        max_ia_loading = net.trafo.at[net_branch_idx, \"sn_mva\"]\n",
    "        if net_branch_idx in trafo_idx_set:\n",
    "            i_star = net_cont.res_trafo.at[net_branch_idx, \"cause_index\"]\n",
    "            max_loading_fraction = net_cont.res_trafo.at[net_branch_idx, \"max_loading_percent\"]\n",
    "            cont_max[j] = net_cont.res_trafo.at[net_branch_idx, \"max_loading_percent\"]\n",
    "        else:\n",
    "            i_star = -1\n",
    "            max_loading_fraction = intact_loading_pct\n",
    "            cont_max[j] = intact_loading_pct\n",
    "    else:\n",
    "        branch_name = \"Unknown\"\n",
    "        intact_loading_pct = 0.0\n",
    "        max_ia_loading = 0.0\n",
    "        i_star = max_loading_indices[j]\n",
    "        cont_max[j] = 0.0\n",
    "    outage_name = \"Unknown\"\n",
    "    if i_star < n_br:\n",
    "        o_net_branch_idx = mapped_branch_idx[i_star]\n",
    "        o_branch_type = mapped_type[i_star]\n",
    "        if o_net_branch_idx != -1:\n",
    "            if o_branch_type == \"line\":\n",
    "                outage_name = net.line.at[o_net_branch_idx, \"name\"]\n",
    "            elif o_branch_type == \"trafo\":\n",
    "                outage_name = net.trafo.at[o_net_branch_idx, \"name\"]\n",
    "    batch_contingency.setdefault(branch_name, []).append(\n",
    "        (intact_loading_pct, max_loading_fraction, outage_name)\n",
    "    )\n",
    "\n",
    "# --- Optimized Aggregation Loop for OTDF Contributions ---\n",
    "#threshold_idx = np.where(max_loading_values >= OVERLOAD_THRESHOLD)[0]\n",
    "# now pick only those branches whose worst‐case loading ≥ OVERLOAD_THRESHOLD\n",
    "threshold_idx = np.where(cont_max >= OVERLOAD_THRESHOLD)[0]\n",
    "contrib_records = []  # list to accumulate tuples of (orig_bus_id, contribution, circuit_debug)\n",
    "p = net.res_bus[\"p_mw\"].to_numpy()\n",
    "q = net.res_bus[\"q_mvar\"].to_numpy()\n",
    "bus_injection = np.sqrt(p**2 + q**2)\n",
    "\n",
    "for j in threshold_idx:\n",
    "    net_branch_idx = mapped_branch_idx[j]\n",
    "    branch_type = mapped_type[j]\n",
    "    if net_branch_idx >= 0:\n",
    "        if branch_type == \"line\":\n",
    "            circuit_debug = circuit_info.get(net_branch_idx, \"UnknownCircuit\")\n",
    "            circuit_rating = net.line.at[net_branch_idx, 'max_i_ka']*net.line.at[net_branch_idx, 'kv_from']*1.732\n",
    "            scaling_factor = net_cont.res_line.at[net_branch_idx, \"max_loading_percent\"]\n",
    "            i_star = net_cont.res_line.at[net_branch_idx, \"cause_index\"]\n",
    "        elif branch_type == \"trafo\":\n",
    "            circuit_debug = f\"Transformer: {net.trafo.at[net_branch_idx, 'name']}\"\n",
    "            circuit_rating = net.trafo.at[net_branch_idx, 'sn_mva']\n",
    "            scaling_factor = net_cont.res_trafo.at[net_branch_idx, \"max_loading_percent\"]\n",
    "            i_star = net_cont.res_trafo.at[net_branch_idx, \"cause_index\"]\n",
    "        else:\n",
    "            circuit_debug = \"UnknownCircuit\"\n",
    "    else:\n",
    "        circuit_debug = \"UnknownCircuit\"\n",
    "\n",
    "    i_star_x = max_loading_indices[j]\n",
    "    row_idx = i_star_x * n_br + j\n",
    "    Xj_unscaled = np.real(OTDF[row_idx, :])\n",
    "    #scaling_factor = max_loading_values[j]\n",
    "    mva_loading_over = ((scaling_factor/100) * circuit_rating) - circuit_rating\n",
    "    #Xj = Xj_unscaled * scaling_factor\n",
    "\n",
    "    nz = np.where(np.abs(Xj_unscaled) >= OTDF_filter)[0]\n",
    "\n",
    "    # Accumulate contributions for all buses at once\n",
    "    for b_idx in nz:\n",
    "        orig_bus_id = new_to_old[b_idx]\n",
    "        sc = Xj_unscaled[b_idx] * scaling_factor\n",
    "        mva_reduction = Xj_unscaled[b_idx] * mva_loading_over\n",
    "        inj = bus_injection[orig_bus_id]\n",
    "        pct_of_injection = (mva_reduction / inj)*100 if inj != 0 else (mva_reduction / 1)*100 #assumes buses with no injection inject at least 1 MVA\n",
    "        bus_name = net.bus['bus_names'].at[orig_bus_id]\n",
    "        contrib_records.append((orig_bus_id,bus_name, sc, scaling_factor, circuit_debug,pct_of_injection))\n",
    "\n",
    "# Convert the records to a DataFrame for efficient grouping.\n",
    "df_contrib = pd.DataFrame(contrib_records, columns=[\"Bus_ID\",\"Bus_Name\", \"Scaled Contribution\",\"Cont_Loading\",\"Circuit_Debug\",\"Percent Reduction\"])\n",
    "\n",
    "# ─── use single contributions DataFrame (df_contrib) ─────────────────────────\n",
    "df = df_contrib.rename(columns={'Scaled Contribution':'scaled_OTDF_Contribution'})\n",
    "\n",
    "# ─── compute the five summary stats, user can change as needed────────────────────\n",
    "statss = (\n",
    "    df.groupby(['Bus_ID','Bus_Name'], as_index=False)['scaled_OTDF_Contribution']\n",
    "      .agg(\n",
    "          Cum_sOTDF = 'sum',\n",
    "          Avg_sOTDF = 'mean',\n",
    "          Med_sOTDF = 'median',\n",
    "          Max_sOTDF = 'max',\n",
    "          Min_sOTDF = 'min'\n",
    "      )\n",
    ")\n",
    "\n",
    "# ─── find the Circuit_Debug at the max/min contribution ─────────────────────────\n",
    "idxmax = df.groupby(['Bus_ID','Bus_Name'])['scaled_OTDF_Contribution'].idxmax()\n",
    "idxmin = df.groupby(['Bus_ID','Bus_Name'])['scaled_OTDF_Contribution'].idxmin()\n",
    "\n",
    "circ_max = (\n",
    "    df.loc[idxmax, ['Bus_ID','Bus_Name','Circuit_Debug','scaled_OTDF_Contribution',\"Cont_Loading\",'Percent Reduction']]\n",
    "      .rename(columns={\n",
    "          'Circuit_Debug':'Circuit_Involved_max',\n",
    "          'scaled_OTDF_Contribution':'Scaled_OTDF_Contribution_max',\n",
    "          'Percent Reduction': 'Percent Reduction_max'\n",
    "      })\n",
    ")\n",
    "circ_min = (\n",
    "    df.loc[idxmin, ['Bus_ID','Bus_Name','Circuit_Debug','scaled_OTDF_Contribution',\"Cont_Loading\",'Percent Reduction']]\n",
    "      .rename(columns={\n",
    "          'Circuit_Debug':'Circuit_Involved_min',\n",
    "          'scaled_OTDF_Contribution':'Scaled_OTDF_Contribution_min',\n",
    "          'Percent Reduction': 'Percent Reduction_min'\n",
    "      })\n",
    ")\n",
    "\n",
    "# ─── stitch together the final table ────────────────────────────────────────────\n",
    "df_agg_final = (\n",
    "    statss\n",
    "      .merge(circ_max, on=['Bus_ID','Bus_Name'], how='left')\n",
    "      .merge(circ_min, on=['Bus_ID','Bus_Name'], how='left')\n",
    ")\n",
    "\n",
    "# ─── write out or return ───────────────────────────────────────────────────────\n",
    "df_agg_final.to_csv(f\"Results/global_agg_final_S{maximize_solar}_W{maximize_wind}.csv\", index=False)\n",
    "print(f\"[Success] Final OTDF aggregator saved\")\n",
    "\n",
    "# Top 5 buses by maximum scaled OTDF contribution\n",
    "top5 = df_agg_final.nlargest(5, 'Max_sOTDF')\n",
    "print(\"=== Top 5 buses by Max_sOTDF ===\")\n",
    "print(top5[['Bus_ID','Bus_Name','Max_sOTDF','Circuit_Involved_max']])\n",
    "\n",
    "# Bottom 5 buses by maximum scaled OTDF contribution\n",
    "bot5 = df_agg_final.nsmallest(5, 'Max_sOTDF')\n",
    "print(\"\\n=== Bottom 5 buses by Max_sOTDF ===\")\n",
    "print(bot5[['Bus_ID','Bus_Name','Max_sOTDF','Circuit_Involved_max']])\n",
    "\n",
    "# Top 5 buses by maximum scaled OTDF contribution\n",
    "top5 = df_agg_final.nlargest(5, 'Cum_sOTDF')\n",
    "print(\"=== Top 5 buses by Cum_sOTDF ===\")\n",
    "print(top5[['Bus_ID','Bus_Name','Cum_sOTDF','Circuit_Involved_max']])\n",
    "\n",
    "# Bottom 5 buses by maximum scaled OTDF contribution\n",
    "bot5 = df_agg_final.nsmallest(5, 'Cum_sOTDF')\n",
    "print(\"\\n=== Bottom 5 buses by Cum_sOTDF ===\")\n",
    "print(bot5[['Bus_ID','Bus_Name','Cum_sOTDF','Circuit_Involved_max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7b0ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#Put from and to bus into line results\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mres_line\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline_id\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m#grab exactly the in‐service metadata from net.line\u001b[39;00m\n\u001b[1;32m    129\u001b[0m meta \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mline\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m    130\u001b[0m     net\u001b[38;5;241m.\u001b[39mline[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_service\u001b[39m\u001b[38;5;124m'\u001b[39m],        \u001b[38;5;66;03m# only in‐service rows\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_bus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_bus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;66;03m# as a list, not separate args\u001b[39;00m\n\u001b[1;32m    132\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def plot_network(results, bus_ids, cont_relevant_results):\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Prepare a color map for power flows\n",
    "    def get_line_color(loading_percent):\n",
    "        return np.interp(loading_percent, [0, 100], [0, 1])\n",
    "    \n",
    "    # Prepare a color map for node LODF\n",
    "    def get_node_color(lodf_pct):\n",
    "        return np.interp(lodf_pct, [0, 100], [0, 1])\n",
    "\n",
    "    # Handle coordinates for buses, bus_names, and annotations\n",
    "    adjusted_coords = {row['index']: (row['x1'], row['y1'], row['bus_names']) for i, row in net.bus.iterrows() if pd.notna(row['x1']) and pd.notna(row['y1']) and row['x1'] not in (0, '') and row['y1'] not in (0, '')}\n",
    "\n",
    "    # Cache annotations for adding them in one go later\n",
    "    annotations = []\n",
    "    traces = []\n",
    "\n",
    "    # Handle bus plotting\n",
    "    for bus_id, (x, y, bus_name) in adjusted_coords.items():\n",
    "        stats = df_agg_final[df_agg_final[\"Bus_Name\"] == bus_name]\n",
    "        if not stats.empty:\n",
    "            cum       = stats[\"Cum_sOTDF\"].iat[0]\n",
    "            max_s     = stats[\"Max_sOTDF\"].iat[0]\n",
    "            circ_max  = stats[\"Circuit_Involved_max\"].iat[0]\n",
    "            min_s     = stats[\"Min_sOTDF\"].iat[0]\n",
    "            circ_min  = stats[\"Circuit_Involved_min\"].iat[0]\n",
    "        else:\n",
    "            cum = max_s = circ_max = min_s = circ_min = \"N/A\"\n",
    "        if isinstance(cum, (int, float, np.floating)):\n",
    "            nc = get_node_color(cum)\n",
    "            node_color = f'rgba({255*nc:.0f}, 0, {255*(1-nc):.0f}, 1)'\n",
    "        else:\n",
    "            node_color = 'rgba(128,128,128,1)'\n",
    "        # Build hover‐text\n",
    "        hover_text = (\n",
    "            f\"<b>Bus {bus_name} (ID {bus_id})</b><br>\"\n",
    "            f\"Cum_sOTDF: {cum}<br>\"\n",
    "            f\"Max_sOTDF: {max_s} (Circuit: {circ_max})<br>\"\n",
    "            f\"Min_sOTDF: {min_s} (Circuit: {circ_min})\"\n",
    "        )\n",
    "\n",
    "        # Add it as a marker trace\n",
    "        traces.append(go.Scatter(\n",
    "            x=[x], y=[y],\n",
    "            text=[hover_text],\n",
    "            hoverinfo=\"text\",\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=12, color=\"blue\"),\n",
    "            name=f\"Bus {bus_id}\"\n",
    "        ))\n",
    "\n",
    "        # Always annotate the bus name\n",
    "        annotations.append(dict(\n",
    "            x=x, y=y, text=bus_name,\n",
    "            showarrow=False,\n",
    "            font=dict(size=10, color=\"#ffffff\"),\n",
    "            bgcolor=node_color,opacity=0.8\n",
    "        ))\n",
    "\n",
    "    #Filter out zero or NaN loading\n",
    "    results = results[ results['loading_percent'].ne(0)\n",
    "                    & results['loading_percent'].notna() ]\n",
    "    # Handle lines plotting\n",
    "    for _, row in results.iterrows():\n",
    "        loading_percent = row['loading_percent']\n",
    "        \n",
    "        # Skip plotting lines if the loading_percent is 0\n",
    "        if loading_percent == 0 or pd.isna(loading_percent):\n",
    "            continue\n",
    "            \n",
    "        from_coords = adjusted_coords.get(net.bus.loc[row['from_bus'],'old_index'])\n",
    "        to_coords = adjusted_coords.get(net.bus.loc[row['to_bus'],'old_index'])\n",
    "\n",
    "        if from_coords and to_coords:\n",
    "            loading_percent = row['loading_percent']\n",
    "            line_color = f'rgba({255 * get_line_color(loading_percent)}, 0, {255 * (1 - get_line_color(loading_percent))}, 1)'\n",
    "            traces.append(go.Scatter(x=[from_coords[0], to_coords[0]], y=[from_coords[1], to_coords[1]],\n",
    "                                     mode='lines', line=dict(color=line_color, width=3),\n",
    "                                     hoverinfo='none'))\n",
    "\n",
    "            mid_x, mid_y = (from_coords[0] + to_coords[0]) / 2, (from_coords[1] + to_coords[1]) / 2\n",
    "\n",
    "            # Check if there's relevant contingency data\n",
    "            contingency_info = cont_relevant_results[cont_relevant_results['Element Name'] == row['name']]\n",
    "            if not contingency_info.empty:\n",
    "                contingency_relevant_pct = contingency_info['Max Loading %'].values[0]\n",
    "                cause_element_name = contingency_info['Cause Element Name'].values[0]\n",
    "            else:\n",
    "                contingency_relevant_pct = \"N/A\"\n",
    "                cause_element_name = \"No data\"\n",
    "\n",
    "            # Add text to display on hover only\n",
    "            text_line = (f\"Line {row['name']}<br>{loading_percent}% loading<br>\"\n",
    "                         f\"{contingency_relevant_pct}% under worst N-1 scenario<br>\"\n",
    "                         f\"Caused by: {cause_element_name}\")\n",
    "            \n",
    "            traces.append(go.Scatter(x=[mid_x], y=[mid_y], text=[text_line], hoverinfo='text', mode='markers',\n",
    "                                     marker=dict(size=5, color=line_color)))\n",
    "\n",
    "            # Add arrow annotation for power flow direction if needed\n",
    "            arrow_x, arrow_y, ax_x, ax_y = (to_coords[0], to_coords[1], from_coords[0], from_coords[1]) if row['p_from_mw'] >= 0 else (from_coords[0], from_coords[1], to_coords[0], to_coords[1])\n",
    "            annotations.append(dict(x=mid_x, y=mid_y, ax=ax_x, ay=ax_y, xref=\"x\", yref=\"y\", axref=\"x\", ayref=\"y\", showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=2, arrowcolor=line_color))\n",
    "\n",
    "    # Add traces and annotations to the figure\n",
    "    fig.add_traces(traces)\n",
    "    fig.update_layout(\n",
    "        annotations=annotations,\n",
    "        title=\"Network Diagram with Power Flow Results\",\n",
    "        showlegend=False,\n",
    "        autosize=True,\n",
    "        margin=dict(l=0, r=0, t=50, b=50),\n",
    "        #width=1000,\n",
    "        #height=800,\n",
    "        yaxis=dict(autorange=\"reversed\")\n",
    "    )\n",
    "    #fig.show()\n",
    "    return fig\n",
    "    \n",
    "#Put from and to bus into line results\n",
    "df = net.res_line.reset_index().rename(columns={'index':'line_id'})\n",
    "\n",
    "#grab exactly the in‐service metadata from net.line\n",
    "meta = net.line.loc[\n",
    "    net.line['in_service'],        # only in‐service rows\n",
    "    ['from_bus','to_bus','name']   # as a list, not separate args\n",
    "]\n",
    "\n",
    "# merge on the shared key line_id ↔ net.line.index\n",
    "results = df.merge(\n",
    "    meta,\n",
    "    left_on='line_id',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "fig = plot_network(results, bus_ids, contingency_output)\n",
    "#Let Plotly's layout be autosized\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    margin=dict(l=20, r=20, t=40, b=20)\n",
    ")\n",
    "\n",
    "#Convert the figure to HTML with responsive config\n",
    "html_str = fig.to_html(\n",
    "    full_html=False,\n",
    "    include_plotlyjs=\"cdn\",\n",
    "    config={\"responsive\": True}  # Make the figure responsive\n",
    ")\n",
    "\n",
    "# Embed it in the notebook.\n",
    "from IPython.display import HTML, display\n",
    "#Wrap it in a div that spans 100% width\n",
    "html_code = f\"\"\"\n",
    "<div style=\"max-width: 100%; margin: 0 auto;\">\n",
    "{html_str}\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c8920",
   "metadata": {},
   "source": [
    "The user also has the ability to list any network element in order to monitor changes to the power flow result caused by the varied dispatches comparing different sensitiities. Sensitivities can be adjusted by the user to compare generator locations, network reinforcements and many more. The plot below demonstrates loading percentages on the monitored element for each of the unique cases where each sensitivity scenario captures an example PV project at differerent nodes. Line loading percentages under the worst case contingency are plotted, but other system result metrics such as bus voltage can be chosen as well:\n",
    "\n",
    "![Loading Percentages for Monitored Element Across Sensitivities](Louth_Lisdrum_Contingency_Plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebbb4b9",
   "metadata": {},
   "source": [
    "**Detailed intact powerflow, contingency and BESS nodal results**\n",
    "\n",
    "- The user can specify which sensitivities they would like to have run in order to compare the results with/without certain elements, network upgrades, or generator sizes. Allowing the user to gage the net impact of select changes and easily compare future options. The amount of unique cases can be reduced or increased as necessary. Users can then review comprehensive bus, line, and transformer intact and contingency results. \n",
    "- Various power flow calculation methods are attempted each time, although typically success is reached by utilizing Newton Raphson initialized in a DC manner with Q limits on each generator enforced. \n",
    "- The results allow the user to compare the worst case contingency to the latest ECP constraint reports. This enables the user to make development decisions that are backed by the most recent load flows in the time periods between new ECP constraint reports. It also has a faster turnaround time compared to other reports and studies completed within the industry.  \n",
    "\n",
    "\n",
    "![Plotly output from powerflow](Plotly_output.png)\n",
    "\n",
    "- For each successful case, the user has the option to create a network diagram to display the power flow results. Plotly is used to display these results from PandaPower. This sample shows output from a wind dominant dispatch with BESS units set to zero in the summer season with peak demand in 2031. \n",
    "- By hovering over the midpoint of each line, the user can determine the line name, intact loading percentage, real and reactive power, worst case loading percentage and the element which causes that worst case overload. Each line is color coded based on intact line loading, turning more red-tinted as the loading increases and blue as the line loading decreases. In the above example, Cahir-Doon experiences a line loading of roughly 100%. Arrows on each line display the real power flow direction. By hovering over each node, results from the test BESS net impact are found, allowing the user to quickly compare which nodes would have a better net loading impact by having a charging or discharging generator connected at the node. \n",
    "- For any specific case, or groups of cases, shift factor analysis can be performed on each worst case contingency. Not only does this provide a comprehensive view of the system as to where additional generation or demand can be placed to have minimal impact on loading, but it also provides a view as to which nodes are likely to be prioritized when curtailment allocation needs to take place to alleviate transmission constraint. This clarity on which constraints become \"governing\" is important as the TSO shifts its perspective as to which network upgrades will be prioritized and renewable generation connecting ahead of select upgrades. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8dc0ce",
   "metadata": {},
   "source": [
    "**Further options and additional functionality**\n",
    "\n",
    "Additional functionality includes but is not limited to:\n",
    "- Nodal hosting capacity analysis\n",
    "- Generator connection method option comparison \n",
    "- Network reinforcement sensitivities\n",
    "- Contingency Analysis\n",
    "\n",
    "Further options under development:\n",
    "- Integration with ChatGPT or Llama for comprehensive queries\n",
    "\n",
    "Advantages and Disadvantages:\n",
    "- Significantly cheaper than TARA or PSSE. \n",
    "- More easily adaptable to various python libraries and packages. \n",
    "- Minimal technical or power system knowledge required. \n",
    "\n",
    "While this tool is not perfect, it provides a quick, light-weight screening for HV transmission nodes in the Irish system. The background data feeding into this tool is reviewed, aggregated, and compared against the latest system information provided publicly by Eirgrid and ESB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roi-power-flow-sample-aukJIi7B-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
